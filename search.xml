<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Elasticsearch Performance Optimization]]></title>
    <url>%2F2019%2F01%2F02%2Felasticsearch-optimize%2F</url>
    <content type="text"><![CDATA[一 部署配置优化篇1. Master Node和Data Node设置 条件允许的情况下Master节点和Data节点分开。 # elasticsearch.yml内配置一个true一个falsenode.master: true # 该节点是否参与master节点选举，master节点最好大于等于3的奇数node.data: true # 该节点是否存储数据 2. Data Node不开启HTTP服务 如果Master节点和Data节点分开，建议Data接点不开启HTTP服务。 # elasticsearch.yml内配置http.enabled: false # 默认开启 3. 使用固态硬盘(SSD) 使用SSD可以显著提高Elasticsearch性能。 4. 避免使用swapping swapping是内存不足时使用硬盘设置的交换空间，因为是硬盘的读写，所以性能较差。这个时候不仅仅es效率低，整个系统都效率降低。 # elasticsearch.yml内配置JVM启动参数,锁定Heap sizebootstrap.mlockall: true 这个配置生效要root用户执行ulimit -l unlimited后，再启动/重启Elasticsearch 5. 堆内存配置 堆内存建议为系统可用内存的50%，但不要超过32G(32G会引起Java指针膨胀)，剩余的50%会被Lucene使用来做索引缓存(Lucene使用堆外内存来存储索引)，提高查询效率。 6. 设置字段缓存fileddata 字段数据缓存主要用于排序字段和计算聚合。将所有的字段值加载到内存中，以便提供基于文档快速访问这些值。 # elasticsearch.yml内配置indices.fielddata.cache.size: 40% # 也可以是具体的值，如4gb。默认是无限制indices.breaker.fielddata.limit: 60% # field数据使用内存限制，默认为JVM堆的60%indices.breaker.fielddata.overhead: 1.03 # Elasticsearch使用这个常数乘以所有fielddata的实际值作field的估算值。默认为 1.03 7. 禁止删除delete_all_indices 防止误删索引。 # elasticsearch.yml内配置action.disable_delete_all_indices: true 二. 开发使用优化篇1. 设置refresh_interval # 可通过setting api设置 curl -XPUT /index_name/_settings -d ' &#123; "index" : &#123; "refresh_interval" : "30s" &#125; &#125; '# 或在mapping的settings中加入设置"settings": &#123;"refresh_interval": "30s"&#125; ES默认是1s 2. 允许的情况下禁用_all _all字段是一个很少用到的字段，它连接所有字段的值构成一个用空格分隔的大string，该string被analyzed和index，但是不被store。当你不知道不清楚document结构的时候， 可以用_all查询等。_all字段需要额外的CPU周期和更多的磁盘。所以，如果不需要_all，最好将其禁用！ # 在mapping的settings中加入设置"_all": &#123;"enabled": false&#125; 3. 允许的情况下禁用_source _source会存储文档的原始字段内容，在查询的时候会返回_source内容，如果禁用查询将只返回_id，但不影响聚合与索引。在特定场景下Elasticsearch只是作为索引时(原始 内容存于其他地方，如HBase)，再根据ID获取内容，可以禁用_source。 # 在mapping的settings中加入设置"_source": &#123;"enabled": false&#125; 4. 批处理_bulk 使用批处理可以提高Elasticsearch的QPS，提高性能。 5. Script脚本使用 尽量避免使用Script，如需使用建议使用painless脚本。 6. 合理的分片数 Elasticsearch创建index后分片数就不可更改，建议每个分片大小在20~30G左右，每GB堆内存的分片数最大控制在20个左右(如堆内存为8G的Node最多存放160个分片)，在存储log这种 读少写多的场景可适当调高。 7. 设计路由(Routing) 一个好的路由规则可以极大地提高Elasticsearch的查询效率。默认是_id字段。 8. 避免深分页查询 Elasticsearch深分页是非常低效的，Elasticsearch查询时会讲匹配的所有分片的查询获取from + size条记录，最后从所有结果集中取size条记录。 Elasticsearch参数max_result_window会限制from + size的最大数，如果大于这个值会抛出异常。该值默认为1000，可以通过setting设置(建议不要设置过大)。 # 可通过setting api设置 curl -XPUT /index_name/_settings -d ' &#123; "index" : &#123; "max_result_window" : 20000 &#125; &#125; ' # 或在mapping的settings中加入设置"settings": &#123;"max_result_window": 20000&#125; 如需深分页，可通过scrollapi实现滚动分页。]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pseudo Distributed Hbase Install]]></title>
    <url>%2F2018%2F10%2F26%2Fpseudo-distributed-hbase-install%2F</url>
    <content type="text"><![CDATA[一. 环境准备1. Ubuntu、JDK8、Hadoop2.8.5、HBase2.1.0 安装Ubuntu https://www.ubuntu.com/download/desktop 安装JDK,修改环境变量 https://www.oracle.com/technetwork/java/javase/downloads/index.html 安装Hadoop2.8.5 http://hadoop.apache.org/ 下载HBase2.1.0 http://hbase.apache.org/ 2. 其他准备 部署Hadoop详见: Hadoop 伪分布式部署 二. 部署HBase1. 解压HBase cd ~sudo tar -zxf ~/Downloads/hbase-2.1.0-bin.tar.gz -C /usr/local # 解压到/usr/local中cd /usr/local/ chmod -R 777 ./hbase-2.1.0 # 设置权限 2. 配置HBase环境变量 export HBASE_HOME=/usr/local/hbase-2.1.0export HBASE_CONF_DIR=$&#123;HBASE_HOME&#125;/confexport HBASE_CLASS_PATH=$&#123;HBASE_CONF_DIR&#125;export PATH=$PATH:$&#123;HBASE_HOME&#125;/bin 3. 修改环境${HBASE_HOME}/conf/hbase-evn.sh配置 # 增加以下配置export JAVA_HOME=/usr/local/jdk1.8.0_181 # JDK根目录export HBASE_MANAGES_ZK=true # 使用HBase自带zookeeper 4. 修改配置文件${HBASE_HOME}/conf/hbase-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://crab2died:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5. 修改文件${HBASE_HOME}/conf/regionservers 将localhost改为crab2died 6. 解决HBase master启动错误 # 执行cp cd /usr/local/hbase-2.1.0cp ./lib/client-facing-thirdparty/htrace-core-3.1.0-incubating.jar ./lib 7. 验证版本 hbase version# 成功则会返回版本信息 三. 启动HBase1. 先启动Hadoop,详见: Hadoop 伪分布式部署2. 启动HBase start-hbase.sh 3. jps查看进程 jps1257 HQuorumPeer1285 HMaster1312 HRegionServer 4. 查看HBase管理界面 http://crab2died:16030 5. 进入命令行管理 hbase shell]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>Big Data</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pseudo Distributed Hadoop Install]]></title>
    <url>%2F2018%2F10%2F26%2Fpseudo-distributed-hadoop-install%2F</url>
    <content type="text"><![CDATA[一. 环境准备准备Ubuntu、JDK8、Hadoop2.8.5 安装Ubuntu https://www.ubuntu.com/download/desktop 安装JDK,修改环境变量 https://www.oracle.com/technetwork/java/javase/downloads/index.html 下载Hadoop2.8.5 http://hadoop.apache.org/ 其他准备1. 更新apt sudo apt-get update2. SSH安装，配置无密码SSH登入2.1. SSH安装 sudo apt-get install openssh-server2.2. 配置SSH无密码登入 cd ~/.ssh/ # 若没有该目录，请先执行一次ssh crab2diedssh-keygen -t rsa # 会有提示，都按回车就可以cat ./id_rsa.pub &gt;&gt; ./authorized_keys # 加入授权ssh crab2died # 验证无密码登入 3. 修改hosts sudo vi /etc/hosts# 添加 本机ip crab2died 二. 安装Hadoop1. 解压Hadoop cd ~sudo tar -zxf ~/Downloads/hadoop-2.8.5.tar.gz -C /usr/local # 解压到/usr/local中cd /usr/local/ chmod -R 777 ./hadoop-2.8.5 # 设置权限 2. 设置Hadoop环境变量 sudo vi /etc/profile# 添加export HADOOP_HOME=/usr/local/hadoop-2.8.5 export PATH=$PATH:$&#123;HADOOP_HOME&#125;/sbin:$&#123;HADOOP_HOME&#125;/bin# 保存执行source /etc/profile 3. 验证Hadoop版本 hadoop version # 成功会返回版本信息 4. 伪分布式配置4.1. 进入${HADOOP_HOME}/etc/hadoop目录中，修改以下文件4.1.1. 修改 hadoop-env.sh 将export JAVA_HOME=${JAVA_HOME}改成export JAVA_HOME=/usr/local/jdk1.8.0_181 # JDK根目录 4.1.2. 修改 core-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/home/crab2died/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://crab2died:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 4.1.3. 修改 hdfs-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;hadoop-cluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/home/crab2died/hadoop/hdfs/nn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt; &lt;value&gt;file:/home/crab2died/hadoop/hdfs/snn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.checkpoint.edits.dir&lt;/name&gt; &lt;value&gt;file:/home/crab2died/hadoop/hdfs/snn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/home/crab2died/hadoop/hdfs/dn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 4.1.4. 先复制cp mapred-site.xml.template mapred-site.xml,再修改 mapred-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 4.1.5. 修改 yarn-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;crab2died&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt; &lt;value&gt;file:/home/crab2died/hadoop/yarn/nm&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5. 格式化HDFS NameNode hdfs namenode -format 6. 启动集群6.1. 启动HDFS集群 hadoop-daemon.sh start namenodehadoop-daemon.sh start datanodehadoop-daemon.sh start secondarynamenode # 伪分布式才有 6.2. 启动YARN yarn-daemon.sh start resourcemanageryarn-daemon.sh start nodemanager 7. jps查看进程 jps1213 NameNOde1261 NodeManager1521 ResourceManager1722 DataNode1732 SecondrayNameNode 8. 查看HDFS管理界面 http://crab2died:50070 9. 查看YARN管理界面 http://crab2died:8088]]></content>
      <categories>
        <category>Big Data</category>
      </categories>
      <tags>
        <tag>Big Data</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Integration Websocket]]></title>
    <url>%2F2018%2F08%2F27%2Fspring-intergration-websocket%2F</url>
    <content type="text"><![CDATA[一. 依赖（这里只列举了websocket相关依赖）&lt;!-- spring webSocket依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-websocket&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-messaging --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-messaging&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/javax.websocket/javax.websocket-api --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.websocket&lt;/groupId&gt; &lt;artifactId&gt;javax.websocket-api&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- websocket客户端 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.glassfish.tyrus.bundles&lt;/groupId&gt; &lt;artifactId&gt;tyrus-standalone-client&lt;/artifactId&gt; &lt;version&gt;1.13&lt;/version&gt;&lt;/dependency&gt; 二. WebSocket服务端2.1. 核心代码package com.github.websocket.server;import com.alibaba.fastjson.JSON;import com.github.CommonConstant;import com.github.session.SObject;import com.github.websocket.configuration.HttpSessionConfigurator;import com.github.websocket.msg.Msg;import org.apache.commons.lang.StringUtils;import org.apache.log4j.Logger;import javax.servlet.http.HttpSession;import javax.websocket.*;import javax.websocket.server.ServerEndpoint;import java.io.IOException;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;/** * @author : Crab2Died&lt;/br&gt; * @DESC : &lt;p&gt;注解&#123;@link ServerEndpoint&#125;声明websocket 服务端&lt;/p&gt;&lt;/br&gt; * @date : 2017/5/25 9:43&lt;/br&gt; */@ServerEndpoint(value = "/chat", configurator = HttpSessionConfigurator.class)public class WSServer &#123; static private Logger logger = Logger.getLogger(WSServer.class); // 在线人数 线程安全 private static int onlineCount = 0; // 连接集合 userId =&gt; server 键值对 线程安全 static public final ConcurrentMap&lt;String, WSServer&gt; map = new ConcurrentHashMap&lt;&gt;(); // 与某个客户端的连接会话，需要通过它来给客户端发送数据 private Session session; // 当前会话的httpsession private HttpSession httpSession; /** * @param session websocket连接sesson * @param config &#123;@link com.github.websocket.configuration.HttpSessionConfigurator&#125; * @DESC &lt;p&gt;注解&#123;@link OnOpen&#125; 声明客户端连接进入的方法&lt;/p&gt; */ @OnOpen public void onOpen(Session session, EndpointConfig config) &#123; // 得到httpSession this.httpSession = (HttpSession) config.getUserProperties().get(HttpSession.class.getName()); // 获取session对象 SObject(这个就是java web登入后的保存的session对象，此处为用户信息，包含了userId) SObject user = (SObject) this.httpSession.getAttribute(CommonConstant.USER_LOGIN_SESSION); this.session = session; // 将连接session对象存入map map.put(user.getUid(), this); // 连接数+1 addOnlineCount(); logger.info("有新的连接，当前连接数为：" + getOnlineCount()); &#125; /** * &lt;p&gt;&#123;@link OnClose&#125; 关闭连接&lt;/p&gt; */ @OnClose public void onClose() &#123; /** * 获取当前连接信息 &#123;@code CommonConstant.USER_LOGIN_SESSION&#125; 为Http session 名 */ SObject user = (SObject) this.httpSession.getAttribute(CommonConstant.USER_LOGIN_SESSION); // 移除连接 map.remove(user.getUid()); // 连接数-1 subOnlineCount(); logger.info("有一连接断开，当前连接数为：" + getOnlineCount()); &#125; /** * &lt;p&gt;&#123;@link OnMessage&#125; 消息监听处理方法&lt;/p&gt; * * @param message 消息对象&#123;@link com.github.websocket.msg.Msg&#125;的JSON对象 * @throws IOException 异常 */ @OnMessage public void onMessage(String message) throws IOException &#123; // 将消息转Msg对象 Msg msg = JSON.parseObject(message, Msg.class); //TODO 可以对msg做些处理... // 根据Msg消息对象获取定点发送人的userId WSServer _client = map.get(msg.getToUid()); // 定点发送 if (StringUtils.isNotEmpty(msg.getToUid())) &#123; if (null != _client) &#123; // 是否连接判断 if (_client.session.isOpen()) // 消息发送 _client.session.getBasicRemote().sendText(JSON.toJSONString(msg)); &#125; &#125; // 群发 if (StringUtils.isEmpty(msg.getToUid())) &#123; // 群发已连接用户 for (WSServer client : map.values()) &#123; client.session.getBasicRemote().sendText(JSON.toJSONString(msg)); &#125; &#125; &#125; /** * &lt;p&gt;&#123;@link OnError&#125; websocket系统异常处理&lt;/p&gt; * * @param t 异常 */ @OnError public void onError(Throwable t) &#123; logger.error(t); t.printStackTrace(); &#125; /** * &lt;p&gt;系统主动推送 这是个静态方法在web启动后可在程序的其他合适的地方和时间调用，这就实现了系统的主动推送&lt;/p&gt; * * @param msg 消息对象&#123;@link com.github.websocket.msg.Msg&#125;的JSON对象 */ static public void pushBySys(Msg msg) &#123; //TODO 也可以实现定点推送 // 群发 for (WSServer client : map.values()) &#123; try &#123; client.session.getBasicRemote().sendText(JSON.toJSONString(msg)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; // 获取连接数 private static synchronized int getOnlineCount() &#123; return WSServer.onlineCount; &#125; // 增加连接数 private static synchronized void addOnlineCount() &#123; WSServer.onlineCount++; &#125; // 减少连接数 private static synchronized void subOnlineCount() &#123; WSServer.onlineCount--; &#125;&#125; 2.2. HttpSessionConfigurator类package com.github.websocket.configuration;import javax.servlet.http.HttpSession;import javax.websocket.HandshakeResponse;import javax.websocket.server.HandshakeRequest;import javax.websocket.server.ServerEndpointConfig;import javax.websocket.server.ServerEndpointConfig.Configurator;/** * @author : Crab2Died&lt;/br&gt; * @DESC : &lt;p&gt;讲http request的session 存入websocket的session内&lt;/p&gt;&lt;/br&gt; * @date : 2017/5/25 16:08&lt;/br&gt; */public class HttpSessionConfigurator extends Configurator &#123; @Override public void modifyHandshake(ServerEndpointConfig sec, HandshakeRequest request, HandshakeResponse response) &#123; // 获取当前Http连接的session HttpSession httpSession = (HttpSession) request.getHttpSession(); // 将http session信息注入websocket session sec.getUserProperties().put(HttpSession.class.getName(), httpSession); &#125;&#125; 2.3. Msg消息体package com.github.websocket.msg;import java.util.Date;/** * @author : Crab2Died&lt;/br&gt; * @DESC : &lt;p&gt;WebSocket消息模型&lt;/p&gt;&lt;/br&gt; * @date : 2017/5/25 9:43&lt;/br&gt; */public class Msg &#123; // 推送人ID private String fromUid; // 定点推送人ID private String toUid; // 定点推送单位ID private String toOrgId; // 消息体 private String data; // 推送时间 private Date createDate = new Date(); // 消息状态 private Integer flag; public Msg() &#123; &#125; public Msg(String fromUid, String toUid, String toOrgId, String data, Date createDate, Integer flag) &#123; this.fromUid = fromUid; this.toUid = toUid; this.toOrgId = toOrgId; this.data = data; this.createDate = createDate; this.flag = flag; &#125; public String getFromUid() &#123; return fromUid; &#125; public void setFromUid(String fromUid) &#123; this.fromUid = fromUid; &#125; public String getToUid() &#123; return toUid; &#125; public void setToUid(String toUid) &#123; this.toUid = toUid; &#125; public String getToOrgId() &#123; return toOrgId; &#125; public void setToOrgId(String toOrgId) &#123; this.toOrgId = toOrgId; &#125; public String getData() &#123; return data; &#125; public void setData(String data) &#123; this.data = data; &#125; public Date getCreateDate() &#123; return createDate; &#125; public void setCreateDate(Date createDate) &#123; this.createDate = createDate; &#125; public Integer getFlag() &#123; return flag; &#125; public void setFlag(Integer flag) &#123; this.flag = flag; &#125; @Override public String toString() &#123; return "Msg&#123;" + "fromUid='" + fromUid + '\'' + ", toUid='" + toUid + '\'' + ", toOrgId='" + toOrgId + '\'' + ", data='" + data + '\'' + ", createDate=" + createDate + ", flag=" + flag + '&#125;'; &#125;&#125; 三. 客户端（HTML5）&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;title&gt;WebSocket&lt;/title&gt;&lt;script type="text/javascript"&gt; // 创建websocket实例 var ws = new WebSocket("ws://localhost:8080/chat"); /* *监听三种状态的变化js会回调 */ ws.onopen = function(message) &#123; // 连接回调 &#125;; ws.onclose = function(message) &#123; // 断开连接回调 &#125;; ws.onmessage = function(message) &#123; // 消息监听 showMessage(message.data); &#125;; //监听窗口关闭事件，当窗口关闭时，主动去关闭websocket连接，防止连接还没断开就关闭窗口，server端会抛异常。 window.onbeforeunload = function() &#123; ws.close(); &#125;; //关闭连接 function closeWebSocket() &#123; ws.close(); &#125; //发送消息 function send() &#123; var input = document.getElementById("msg"); var text = input.value; // 消息体JSON 对象 对应JAVA 的 Msg对象 var data = &#123; // 定点发送给其他用户的userId toUid : "3d535429-5fcb-4490-bcf7-96fd84bb17b6", data : text &#125; ws.send(JSON.stringify(data)); input.value = ""; &#125; function showMessage(message) &#123; var text = document.createTextNode(JSON.parse(message).data); var br = document.createElement("br") var div = document.getElementById("showChatMessage"); div.appendChild(text); div.appendChild(br); &#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; style="width: 600px; height: 240px; overflow-y: auto; border: 1px solid #333;" id="show"&gt; &lt;div id="showChatMessage"&gt;&lt;/div&gt; &lt;input type="text" size="80" id="msg" name="msg" placeholder="输入聊天内容" /&gt; &lt;input type="button" value="发送" id="sendBn" name="sendBn" onclick="send()"&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>Web Socket</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Web Socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful HTTP]]></title>
    <url>%2F2018%2F08%2F27%2Frestful-http%2F</url>
    <content type="text"><![CDATA[一. REST由来 REST(Representational State Transfer 表征性状态转移) 2000年Roy Fielding的博士论文中首次提出 REST是架构风格，是设计思想，不是标准也不是协议 REST强调组件交互的可伸缩性、接口的通用性、组件的独立部署、以及用来减少交互延迟、增强安全性、封装遗留系统的中间组件 二. REST特点 服务端(server)与客户端(client)解耦 简化服务端的可伸缩性，提高客户端便捷性 面向资源，每一个资源都有唯一(CRUD等操作不会变)的标识符 无状态(Stateless)，请求必须包含所有处理该请求的全部信息 提高可见性，每个请求都是独立的，无需其他依赖的 提高可靠性，故障恢复更容易 提升扩展性，减少了服务器资源消耗 可缓存(Cachable) 减少交互次数，减少网络延时 分层系统(Layered System) 允许Client与Server中间层(代理，网关等)代替Server端处理请求，客户端无需关心与他交互组件的其他之外的事 提高了系统可扩展性，简化系统复杂度 统一接口(Uniform Interface) 服务端与客户端统一化的方法(GET/PUT/POST/DELETE)通信 提高了接口的可见性 按需代码(Code-On-Demand) 提升系统可扩展性 三. 为什么要遵循REST 可更高效利用缓存来提高响应速度 通讯本身的无状态性可以让不同的服务器的处理一系列请求中的不同请求，提高服务器的扩展性 浏览器即可作为客户端，简化软件需求 相对于其他叠加在HTTP协议之上的机制，REST的软件依赖性更小 不需要额外的资源发现机制 在软件技术演进中的长期的兼容性更好 四. RESTful最佳实践 URI规则 版本化(其一) 如: /api/v1 使用名词，而不是动词 如: blog 使用小写，用 _做词连接，而不用- 表示资源集合时，使用复数形式 如: blogs 子资源关系表示 示例: /blog/100/comments 为减少URI层级深度,引入适当的参数查询 Request Method (资源的CRUD) GET/HEAD : 查询资源 GET /blog/100 GET /blog/100/comments POST: 创建资源 POST /blog POST /blog/100/comment PUT/PATCH: 更新资源 PUT /blog/100 PUT /blog/100/comment/1 DELETE: 删除资源 DELETE /blog/100 DELETE /blog/100/comment/1 Response 一般地，返回JSON数据而不是XML 不过滤API返回的空格，支持gzip/deflate压缩,Content-Encoding: gzip/deflate 统一的返回格式，错误码信息等 常见HTTP status 200 OK - 对成功的GET、PUT、PATCH或DELETE操作进行响应。也可以被用在不创建新资源的POST操作上 201 Created - 对创建新资源的POST操作进行响应。应该带着指向新资源地址的Location header 204 No Content - 对不会返回响应体的成功请求进行响应（比如DELETE请求） 304 Not Modified - HTTP缓存header生效的时候用 400 Bad Request - 请求异常，比如请求中的body无法解析 401 Unauthorized - 没有进行认证或者认证非法。当API通过浏览器访问的时候，可以用来弹出一个认证对话框 403 Forbidden - 当认证成功，但是认证过的用户没有访问资源的权限 404 Not Found - 当一个不存在的资源被请求 405 Method Not Allowed - 所请求的HTTP方法不允许当前认证用户访问 410 Gone - 表示当前请求的资源不再可用。当调用老版本API的时候很有用 415 Unsupported Media Type - 如果请求中的内容类型是错误的 422 Unprocessable Entity - 用来表示校验错误 429 Too Many Requests - 由于请求频次达到上限而被拒绝访问 认证 RESTful API无状态的，每个请求都要自带凭证。 使用基于SSL来保证传输安全的OAauth 2 缓存 强制缓存 Cache-Control与Expires 比对缓存 1、Last-Modified与If-Modified-Since 2、Etag与If-None-Match HATEOAS (Hypermedia as the Engine of Application State) 超媒体作为应用状态的引擎，即在返回结果中提供链接,指向其他API,为用户调用提供指引信息。如: 当调用http://api.blog.com 时返回 &#123; "link": &#123; "rel": "collection https://www.blog.com/blogs", "href": "https://api.blog.com/blogs", "title": "List of blogs", "type": "application/vnd.yourformat+json" &#125;&#125; rel 表示与该API的关系，href表示指引API的链接，title表示API的标题，type表示接受类型 HTTP Request Method覆盖 一些老的HTTP Client只支持GET、POST请求，为了兼容这些Client，API需要覆盖HTTP方法，一般做法是HTTP POST请求会有一个 X-HTTP-Method-Override请求头，其值为PUT,PATCH,DELETE之一,以此兼容请求。 限制速度 避免请求泛滥，HTTP引入状态码429(Too Many Requests) 一般地，是返回头信息(依照twitter的命名规则) X-Rate-Limit-Limit: 当前时间段允许的并发请求数 X-Rate-Limit-Remaining: 当前时间段保留的请求数。 X-Rate-Limit-Reset: 重置时间(秒) Retry-After: 下一次访问应该等待的时间(秒)]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>REST</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Cache Summarize]]></title>
    <url>%2F2018%2F07%2F16%2Fredis-cache-summarize%2F</url>
    <content type="text"><![CDATA[1. 概述 Redis全称: Remote Dictionary Server 基于内存的Key-Value存储系统，单线程实现 多样的数据类型，支持的数据类型有：string(字符串)、hash(哈希)、list(链表)、set(集合)、zset(sorted set有序集合) redis的value大小可达到1GB(memcach只能达到1MB) 持久化，redis会周期性的将更新的数据写入磁盘 master-slave(主从)同步 3.0后支持分布式存储，去中心化，具有线性伸缩功能 Redis命令大全 2. Redis数据持久化2.1. RDB(Redis DataBase) SNAPSHOT(快照): save 秒数 写操作次数如save 9000 1表示900s(15min)有一次写操作生成快照，也可save &quot;&quot;表示 每次写操作即生成快照 配置stop-writes-on-bgsave-error yes/no当后台生成快照错误是否中断redis写操作的支持 配置rdbcompression yes/no表示是否压缩RDB文件 每次会fork一份来重启另一个进程进行持久化 2.2. AOF(Append Only File) 配置appendonly no/yes启用AOF，启动时会触发全量写文件，后面写操作是增量写文件 同步策略配置appendfsync always(每次写操作都触发同步)/everysec(每秒同步一次)/no(不同步) 重写(rewrite): 满足条件后触发重写，会对AOF文件内容优化，减少文件大小auto-aof-rewrite-percentage 100 (表示超过文件的百分比)auto-aof-rewrite-min-size 64mb (触发重写的最小文件大小) AOF文件修复: redis-check-aof --fix appendonly.aof 2.3. 比较 RDB安全性较差、容易丢失最近一次缓存内容，但文件较小，恢复速度较快，是Master/Slave主从复制模式下的最好补充 AOF更加安全、数据的完整性较强、但文件较大、恢复速度较慢，IO开支较大，比较影响性能 Redis启用默认是脚在AOF文件恢复数据 2.4. 缓存驱逐策略 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction：禁止驱逐数据 3. Redis集群3.1. 分片策略 Redis集群被分为16384(214)个hash slot(hash槽)，集群内每个节点都拥有部分hash槽，使用数据键的CRC16编码对16384取模来 计算数据对应的hash槽，Redis最大节点数为16384 Redis集群新增节点只用把集群中每个节点的部分hash槽移动到新节点中即可 Redis集群移除节点也只用把该节点的hash槽移动到其他节点即可 Redis集群之间是异步复制 3.2. 架构分析 所有的redis节点彼此互联(PING-PONG 机制),内部使用二进制协议优化传输速度和带宽. 节点的fail是通过集群中超过半数的节点检测失效时才生效 客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可]]></content>
      <categories>
        <category>Cache</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Database]]></title>
    <url>%2F2018%2F07%2F06%2Fdatabase%2F</url>
    <content type="text"><![CDATA[一. 四大特性(CIAD) 原子性(Atomicity): 要么全成功，要么全失败，失败会回滚。 一致性(Consistency): 一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执 行之前和执行之后都必须处于一致性状态。 隔离性(Isolation): 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务， 不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 持久性(Durability): 一旦事物提交成功，那么数据库中的数据就是永久改变的，即使系统故障也不会丢失提交的事物。 二. 数据库隔离级别1. 不考虑隔离级别造成的问题 更新丢失: 2个事物同时更新一条数据会有一个事物把另一个事物的更新覆盖了，这是因为系统没有任何操作隔离导致的. 脏读: 一个事物读取了另一个事物还未提交事物的数据 不可重复读: 一个事务对同一行数据重复读取两次，但是却得到了不同的结果 虚读: 一个事物去改变数据改变后发现还有数据为按要求改变，是因为另一事物也做了改变的缘故 幻读: 同一个事物内多次查询返回的结果不一致，是因为另一事物对数据进行了改变 2. 隔离级别(低 -&gt; 高) Read uncommitted(未授权读取、读未提交) 当一个事物在执行写操作时，则不允许另一事物执行写操作，可执行其他操作，可由排他锁来实现 解决了更新丢失问题，但会出现脏读 Read committed(授权读取、读提交) 读取数据事物允许其他事物继续访问该数据，但未提交的数据禁止其他事物访问 避免了脏读，但可能会出现幻读 Repeatable read(可重复读取) 读数据的事物将禁止写事物(可以读事物),写事物将禁止所有其他事物 避免了脏读和不可重复读，但可能会出现幻读 Serializable(序列化) 事物严格按照顺序一个一个执行 能避免所有情况，但会极大影响系统性能 3. 扩展 大多数数据库的默认级别就是Read committed，比如Sql Server , Oracle。 Mysql的默认隔离级别就是Repeatable read。 MySQL数据库隔离级别管理 查看隔离级别: select @@tx_isolation 修改隔离级别:set [glogal | session] transaction isolation level 隔离级别名称如set transaction isolation level read-committed或者set tx_isolation=&#39;隔离级别名称&#39; 如 set tx_isolation = &#39;read-committed&#39; 隔离级别的设置只对当前连接有效 4. MySQL悲观锁、乐观锁、共享锁与排他锁 悲观锁: 在操作数据时都认为会出现数据冲突，所以每次都会去获取锁，只有获取锁后才能对数据操作。 乐观锁: 在操作数据都认为不会发生数据冲突，可以直接操作，一般由用户通过版本号自己实现。 共享锁: 共享锁指的就是对于多个不同的事务，对同一个资源共享同一个锁。在SQL后面加上lock in share mode表示使用共享锁。 排他锁: 排它锁与共享锁相对应，就是指对于多个不同的事务，对同一个资源只能有一把锁。与共享锁类型，在需要执行的 语句后面加上for update就可以了。 三. 数据库的三大范式(Normal Form) 第一范式(1NF)：强调的是列的原子性，即列不能够再分成其他几列。 第二范式(2NF)：一个表必须有一个主键，二是其他列必须完全依赖于主键，而不能依赖主键一部分 第三范式(3NF)：非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列A依赖于非主键列B，非主键列B依赖于主键的情况。 四. 数据库数据结构 B+ Tree 相较于B Tree多了一层，只有树的叶子节点存储实际数据，方便了range查询操作 五. mysql的MyISAM与InnoDB show engines 查看当前引擎与默认引擎 设置表引擎 CREATE后面加CREATE TABLE &quot;&quot; () ENGINE=MyISAM 或 alter table 表名 ENGINE = InnoDB 比较 MyISAM不支持事物,InnoDB支持 InnoDB支持行锁定,MyISAM不支持，只支持表锁定 InnoDB支持外键,MyISAM不支持 MyISAM支持全文检索,InnoDB不支持 MyISAM内置一个数据计数器，能很容易得出SELECT COUNT(*) FROM TABLE_NAME结果 MyISAM索引数据与表数据分离，而InnoDB索引与表数据紧密关联 六. SQL功能 数据定义(DDL)：用于定义SQL模式、基本表、视图和索引的创建和撤消操作 数据操纵(DML)：数据操纵分成数据查询和数据更新两类。数据更新又分成插入、删除、和修改三种操作 数据控制：包括对基本表和视图的授权，完整性规则的描述，事务控制等内容 嵌入式SQL使用规定：涉及到SQL语句嵌入在宿主语言程序中使用的规则]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Classloader]]></title>
    <url>%2F2018%2F06%2F25%2Fjava-classloader%2F</url>
    <content type="text"><![CDATA[1. 类加载时机1.1. 生命周期 1.2. 立即初始化(主动引用) 遇到new、 getstatic、 putstatic或invokestatic这4条字节码指令时 使用java.lang.reflect包的方法对类进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化. 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化. 当虚拟机启动时,用户需要指定一个要执行的主类(包含main()方法的那个类),虚拟机会先初始化这个主类. 当使用JDK 1.7的动态语言支持时,如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、 REF_putStatic、REF_invokeStatic的方法句柄,并且这个方法句柄所对应的类没有进行过初始化,则需要先触发其初始化. 1.3. 被动加载 子类调用父类静态方法,子类不会被初始化 引用类型定义不初始化加载 常量调用不会初始化类(编译期已进入常量池) 1.4. 接口初始化 &emsp;&emsp;当一个类在初始化时,要求其父类全部都已经初始化过了,但是一个接口在初始化时,并不要求其父接口全部都完成了初始化, 只有在真正使用到父接口的时候(如引用接口中定义的常量)才会初始化. 2. 类加载过程2.2. 加载 通过一个类的全限定名来获取定义此类的二进制字节流(这一条玩出了很多技术,如:jsp(从其他文件中生成),Applet(从网络中获取),Proxy(运行时计算)). 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构. 在内存中生成一个代表这个类的java.lang.Class对象,作为方法区这个类的各种数据的访问入口. 注:&emsp;&emsp;加载阶段完成后,虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中,方法区中的数据存储格式由虚拟机实现自行定义, 虚拟机规范未规定此区域的具体数据结构. 然后在内存中实例化一个java.lang.Class类的对象(并没有明确规定是在Java堆中, 对于HotSpot虚拟机而言,Class对象比较特殊,它虽然是对象,但是存放在方法区里面),这个对象将作为程序访问方法区中的这些类型数据的外部接口. 2.3. 验证 &emsp;&emsp;确保Class文件的字节流中包含的信息符合当前虚拟机的要求,并且不会危害虚拟机自身的安全. -Xverify:none 参数来关闭大部分的类验证措施,以缩短虚拟机类加载的时间. 文件格式验证 魔数0xCAFEBABE验证 主、次版本号验证 常量池常量验证 UTF-8编码验证 … 元数据验证 这个类是否有父类 该类是否继承了不能继承的类(如:final类) … 字节码验证第三阶段是整个验证过程中最复杂的一个阶段,主要目的是通过数据流和控制流分析,确定程序语义是合法的、 符合逻辑的. 保证跳转指令不会跳转到方法体以外的字节码指令上. 保证方法体中的类型转换是有效的 … 符号引用验证 符号引用中通过字符串描述的全限定名是否能找到对应的类. 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段. 符号引用中的类、 字段、 方法的访问性(private、 protected、 public、 default)是否可被当前类访问 (不通过将抛一个IncompatibleClassChangeError异常子类). … 2.4. 准备 &emsp;&emsp;准备阶段是正式为类变量分配内存并设置类变量初始值的阶段,这些变量所使用的内存都将在方法区中进行分配. 注:内存分配仅包括类变量(static修饰),不包括实例变量;初始值通常是指零值(如:public static int v = 123; 初始值v为0而非123, 但如public static final int v = 123;时将被初始化为123) 2.5. 解析 &emsp;&emsp;解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程 符号引用(Symbolic References) 直接引用(Direct References) 虚拟机对除invokedynamic(动态调用点限定符)指令外的操作进行缓存 解析动作主要针对类或接口、 字段、 类方法、 接口方法、 方法类型、 方法句柄和调用点限定符7类符号引用进行, 分别对应于常量池的CONSTANT_Class_info、CONSTANT_Fieldref_info、 CONSTANT_Methodref_info、 CONSTANT_InterfaceMethodref_info、 CONSTANT_MethodType_info、CONSTANT_MethodHandle_info 和CONSTANT_InvokeDynamic_info 7种常量类型 1)类或接口解析 2)字段解析 3)类方法解析 4)接口方法解析 2.6. 初始化 &emsp;&emsp;类加载的最后一步,真正执行java的字节码.&lt;clinit&gt;()方法保证在子类执行之前父类的&lt;clinit&gt;()已执行完毕.虚拟机中第一个被执 行的&lt;clinit&gt;()方法的类肯定是java.lang.Object.&lt;clinit&gt;()虚拟机保证只执行一次,多线程时只会有一条线程执行,其他线程阻塞等待. 2.7. 卸载3. 类加载器 描述: 通过一个类的全限定名来获取描述此类的二进制字节流 应用: 类层次划分、热部署、OSGi(面向Java的动态模型系统)、代码加密等 3.1. 类与类加载器 相同的类被不同的类加载器加载他们必不相等. 3.2. 双亲委派模型(Parents Delegation Model)3.2.1. 类加载器 启动类加载器(Bootstrap ClassLoader)C++实现、虚拟机一部分 又称 引导类加载器 按名识别,如:rt.jar 负责加载&lt;JAVA_HOME&gt;\lib目录或被参数-Xbootclasspth指定的目录 其他类加载器, java实现,独立与虚拟机外部,全部继承抽象类java.lang.ClassLoader 扩展类加载器(Extension ClassLoader) 由sun.misc.Launcher$ExtClassLoader类实现 负责加载&lt;JAVA_HOME&gt;\lib\ext目录或参数-Djava.ext.dirs所指定目录下的类 应用程序类加载器(Application ClassLoader) 又称 系统类加载器 由sun.misc.Launcher$AppClassLoader实现 它负责加载用户类路径(ClassPath)上所指定的类库,开发者可以直接使用这个类加载器,是程序中默认的类加载器 3.2.2. 双亲委派模型图 自定义类加载器(CustomClassLoader) /启动类加载器 &lt;-- 扩展类加载器 &lt;-- 应用程序加载器 &lt;-- \ 自定义类加载器(CustomClassLoader) &emsp;&emsp;双亲委派模型的工作过程是:如果一个类加载器收到了类加载的请求,它首先不会自己去尝试加载这个类,而 是把这个请求委派给父类加载器去完成,每一个层次的类加载器都是如此,因此所有的加载请求最终都应该传送到顶层的启动类加载器中, 只有当父加载器反馈自己无法完成这个加载请求(它的搜索范围中没有找到所需的类)时,子加载器才会尝试自己去加载 3.3. 破坏双亲委派模型4. 问题4.1. 为什么要用双亲委派类加载 &emsp;&emsp;双亲委派模型可以防止内存中出现多分同样的字节码，如果没有双亲委派模型的话如果用户编写了一个java.lang.Object的同 名类放在classpath中，多个类加载器去加载这个类到内存中系统会出现多个不同的Object类，那么类之间的比较结果及类的唯一性将无法 保证，而且如果不使用这种模型将给虚拟机带来安全隐患。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>Classloader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Compile and Optimize]]></title>
    <url>%2F2018%2F06%2F17%2Fjava-compile-and-optimize%2F</url>
    <content type="text"><![CDATA[1. 早期(编译期)优化1.1. 概论 前端编译器:Sun的Javac、 Eclipse JDT中的增量式编译器(ECJ) JIT编译器:HotSpot VM的C1、 C2编译器 AOT编译器:GNU Compiler for the Java(GCJ)、 Excelsior JET javac这类编译器几乎不对代码进行性能优化,把性能优化放到了JIT即时编译器内,可为JRuby、Groovy这类语言的代码也同等享有优化带来的好处 1.2. javac编译1.2.1. 编译过程 解析与填充符号表过程 词法、语法分析 词法分析是将源代码的字符流转变为标记(Token)集合,单个字符是程序编写过程的最小元素,而标记则是编译过程的最小元素,关键字、 变量名、 字面量、 运算符都可以成为标记 语法分析是根据Token序列构造抽象语法树的过程,抽象语法树(Abstract Syntax Tree,AST)是一种用来描述程序代码语法结构的树形表示方式,语法树的每一个节点都代表着程序 代码中的一个语法结构(Construct),例如包、 类型、 修饰符、 运算符、 接口、 返回值甚至代码注释等都可以是一个语法结构. 填充符号表 符号表(Symbol Table)是由一组符号地址和符号信息构成的表格 在语义分析中,符号表所登记的内容将用于语义检查(如检查一个名字的使用和原先的说明是否一致)和产生中间代码.在目标代码生成阶段,当对符号名进行地址分配时,符号表是地址分配的依据. 插入式注解处理器的注解处理过程 分析与字节码生成过程 标注检查 检查的内容包括诸如变量使用前是否已被声明、 变量与赋值之间的数据类型是否能够匹配等 常量折叠 如定义了int a = 1 + 2会被编译为int a = 3 数据及控制流分析 数据及控制流分析是对程序上下文逻辑更进一步的验证,它可以检查出诸如程序局部变量在使用前是否有赋值、 方法的每条路径是否都有返回值、 是否所有的受查异常都被正确处理了等问题. 语法糖 语法糖:也称糖衣语法,是由英国计算机科学家彼得·约翰·兰达(Peter J.Landin)发明的一个术语, 指在计算机语言中添加的某种语法,这种语法对语言的功能并没有影响,但是更方便程序员使用. 通常来说,使用语法糖能够增加程序的可读性,从而减少程序代码出错的机会. java语法糖:泛型、变长参数、 自动装箱/拆箱等 内部类、 枚举类、 断言语句、 对枚举和字符串(在JDK 1.7中支持) 的switch支持、 try语句中定义和关闭资源(在JDK 1.7中支持)等 泛型:编译器会进行解泛,所以泛型不能进行方法重载 自动装箱、 拆箱与遍历循环 条件编译 if 的条件为常量时编译期会被执行 字节码生成 字节码生成阶段不仅仅是把前面各个步骤所生成的信息(语法树、 符号表)转化成字节码写到磁盘中, 编译器还进行了少量的代码添加和转换工作. 2. 晚期(运行期)优化2.1. 即时编译器(JIT) 为了提高热点代码的执行效率,在运行时,虚拟机将会把这些代码编译成与本地平台相关的机器码,并进行各种层次的优化, 完成这个任务的编译器称为即时编译器(Just In Time Compiler) 解释器与编译器(sun HotSpot虚拟机为例) 交互模型 +---------------即时编译-----------↓ ↓ Client Compiler(C1编译器)解释器(Interpreter) 编译器 ↑ Server Compiler(C2编译器) +----------------逆优化------------↑ HotSpot虚拟机同时由解释器与编译器搭配使用(成为混合模式(Mixed Model)), 可添加参数-Xint强制虚拟机使用解释模式(Interpreted Mode),可添加参数-Xcomp强制虚拟机使用编译模式(Compiled Mode) 启动参数-client启用Client Compiler编译器 参数-server启用Server Compiler编译器 HotSpot虚拟机还会逐渐启用分层编译(Tiered Compilation)的策略,分层编译的概念在JDK 1.6时期出现, JDK1.7中Server模式中默认开启,之前需配参数-XX:+TieredCompilation启用 编译对象与触发条件 触发条件 被多次调用的方法 被多次执行的循环体,这个称为栈上替换(On Stack Replacement,简称为OSR编译) 热点代码判定 基于采样的热点探测,周期性检测个线程的栈顶,若某个方法经常在栈顶,则认为是热点方法； 优点是实现简单简单,高效,容易获取方法调用关系,缺点是不能准确判定一个方法的热度 基于计数器的热点探测,虚拟机为每个方法设定计数器,统计方法执行次数,若超过一定阈值则认为是热点方法； 优点是能准确判定一个方法的热度,缺点是要为每个方法建立计数器并维护,实现麻烦,也不能获取方法的调用关系 HotSpot虚拟机是基于计数器的热点探测,有2个计数器:方法调用计数器(Invocation Counter)和回边计数器(Back Edge Counter) 方法调用计数器,Client模式下阈值为1500次,Server模式下阈值为1000次,可由参数-XX:CompileThreshold来设置 -XX:-UseCounterDecay设置关闭热度衰减,-XX:CounterHalfLifeTime参数设置半衰周期的时间,单位是秒 回边计数器,参数-XX:OnStackReplacePercentage来间接调整回边计数器的阈值Client模式下阈值计算公式:方法调用计数器阈值(CompileThreshold)×OSR比率(OnStackReplacePercentage)[默认值为933]/100 默认情况下为13995Server模式下阈值计算公式:方法调用计数器阈值(CompileThreshold)×(OSR比率(OnStackReplacePercentage)[默认值140]-解释器监控比率(InterpreterProfilePercentage)[默认值33]/100 默认情况下为10700 编译过程 Client模式下编译过程 Server模式下编译过程相当复杂 优化技术 公共子表达式消除 经典优化技术,如果一个表达式E已经计算过了,并且从先前的计算到现在E中所有变量的值都没有发生变化,那么E的这次出现就成为了公共子表达式. 对于这种表达式,没有必要花时间再对它进行计算,只需要直接用前面计算过的表达式结果代替E就可以了 数组边界检查消除 语言相关的其他消除操作还有不少,如自动装箱消除(Autobox Elimination)、 安全点消除(Safepoint Elimination)、消除反射(Dereflection)等 方法内联 虚拟机最重要的优化手段之一,除了消除方法调用的成本之外,它更重要的意义是为其他优化手段建立良好的基础 非虚方法直接内联,虚方法引入了一种名为“类型继承关系分析”(Class Hierarchy Analysis,CHA)的技术, 检查发现没有多个目标版本可供选择,则也可内联,但需准备一个逃生门,即使有多个版本目标也会默认内联,但在调用时要检查, 发现版本目标不一致在取消内联,会从“逃生门”回到解释状态重新执行 逃逸分析(JDK1.6) 当下java最前沿的优化技术 逃逸分析的基本行为就是分析对象动态作用域:当一个对象在方法中被定义后,它可能被外部方法所引用, 例如作为调用参数传递到其他方法中,称为方法逃逸. 甚至还有可能被外部线程访问到, 譬如赋值给类变量或可以在其他线程中访问的实例变量,称为线程逃逸. 栈上分配(Stack Allocation),如果证明一个对象不会逃逸到方法之外,则可以将对象分配到方法栈帧内存,这样随着栈帧出栈而销毁,极大地降低了GC系统压力 同步消除(Synchronization Elimination),如果能证明一个变量不会逃逸出线程,那就可以消除掉同步措施,消除同步带来的消耗 标量替换(Scalar Replacement) 标量(Scalar),是指一个数据已经无法再分解成更小的数据来表示了,如:int,long,double等 聚合量(Aggregate),是指一个数据可以被分解,典型的java对象 如果证明一个对象不被外界访问,又可拆散的话,那程序在调用的时候就不创建该变量,改为创建多个成员变量来代替, 将对象拆分后,除了可以让对象的成员变量在栈上(栈上存储的数据,有很大的概率会被虚拟机分配至物理机器的高速寄存器中存储) 分配和读写之外,还可以为后续进一步的优化手段创建条件 逃逸分析尚不成熟]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JIT</tag>
        <tag>Optimize</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java GC]]></title>
    <url>%2F2018%2F06%2F15%2Fjava-gc%2F</url>
    <content type="text"><![CDATA[一. Java虚拟机内存区域1. 运行时数据区 2. 程序计数器(Program Counter Register) 1、程序计数器是线程内(每个线程都有唯一的、封闭的)一小块内存区域 2、计数器指定的是当前虚拟机执行指令的地址 3、当虚拟机执行的是Native方法时,计数器值为空(Undefined),此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError 情况的区域. 3. Java虚拟机栈(Java Virtual Machine Stacks) 1、虚拟机栈是线程内部的、封闭的 2、虚拟机栈描述的是java方法执行的内存模型 3、每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表、 操作数栈、 动态链接、 方法出口等信息 4、java方法的执行就是入栈与出栈的过程 5、如果虚拟机栈深度超出了虚拟机允许深度将会抛出StackOverflowError异常,现代虚拟机大多数支持动态扩展(也允许固定长度),当虚拟机申 请扩展时申请不到足够的内存时,将会抛出OutOfMemoryError异常 4. 本地方法栈(Native Method Stack) 1、为虚拟机调用本地Native方法提供服务 2、也有虚拟机(譬如Sun HotSpot虚拟机)直接就把本地方法栈和虚拟机栈合二为一 3、也会抛出StackOverflowError异常和OutOfMemoryError异常 5. Java堆(Java Heap) GC堆 1、线程共享的最大一块内存区域 2、此内存区域的唯一目的就是存放对象实例,几乎所有的对象实例都在这里分配内存,虚拟机规范所有的对象实例与数据都在堆上分配 3、随着JIT编译器的发展与逃逸分析技术逐渐成熟,栈上分配、 标量替换优化技术将会导致一些微妙的变化发生,所有的对象都分配在堆上也渐渐 变得不是那么“绝对”了 6. 方法区(Method Area) 1、存储已被虚拟机加载的类信息、 常量、 静态变量、 即时编译器编译后的代码等数据 2、这区域的内存回收目标主要是针对常量池的回收和对类型的卸载 7. 运行时常量池(Runtime Constant Pool) 1、Class文件中除了有类的版本、 字段、 方法、 接口等描述信息外,还有一项信息是常量池(Constant Pool Table),用于存放编译期生成 的各种字面量和符号引用,这部分内容将在类加载后进入方法区的运行时常量池中存放 2、String.intern()也会放入运行时常量池中 8. 直接内存(Direct Memory) 1、NIO的DirectByteBuffer对象使用直接内存,这样能在一些场景中显著提高性能,因为避免了在Java堆和Native堆中来回复制数据 二. Java对象1. 对象的创建 1、指针碰撞(Bump the Pointer) 2、空闲列表(Free List) 2. 对象再内存中的布局 1、分为3块区域:对象头(Header)、实例数据(Instance Data)和对齐填充(Padding) 2、对象头包含:轻量级锁定、 重量级锁定、 GC标记、 可偏向 3. 对象的访问定位 1、句柄访问 2、直接指针访问 三. 垃圾回收与内存分配1. 引用计数法(虚拟机未使用) 1、互相引用将无法得到正常回收 2. 可达性分析算法(Reachability Analysis) 1、通过GC Root节点向下搜索,搜索走过的路径称为引用链(Reference Chain),当一个对象没有一个引用链经过,则表示该对象是不可用的,可以回收 2、可作为GC Root对象的有: 虚拟机栈(栈帧中的本地变量表)中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI(即一般说的Native方法)引用的对象 3. 引用 1、强引用(Strong Reference): new 关键字 2、软引用(Soft Reference):当要发生内存溢出时会将软引用对象加入回收队列中 3、弱引用(Weak Reference):只能活到下次GC前 4、虚引用(Phantom Reference):幽灵引用或者幻影引用 4. 回收方法区 1、主要回收永久代的废弃的常量和无用的类 2、无用的类判定条件: 该类所有的实例都已经被回收,也就是Java堆中不存在该类的任何实例. 加载该类的ClassLoader已经被回收. 该类对应的java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类的方法. 四. 垃圾回收算法1. 标记-清除算法(Mark-Sweep) 1、标记与清除2个过程 2、标记与清除效率都不高,还可能产生大量空间碎片导致大对象找不到连续可用的空间 2. 复制算法(Copying) 1、将堆内存分为大小相等的2块,每次只是用其中一块,当一块内存用完时将还活着的对象移动到另一块,然后清理该块内存 2、消除了内存碎片化,代价是牺牲了一半可用堆内存 3、商用虚拟机都采用这种,但并不是按1:1来划分空间而是将内存分为一块较大的Eden空间和两块较小的Survivor空间,每次使用Eden和其中 一块Survivor.当回收时,将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上,最后清理掉Eden和刚才用过的 Survivor空间. HotSpot虚拟机默认Eden和Survivor的大小比例是8:1,也就是每次新生代中可用内存空间为整个新生代容量的 90%(80%+10%),只有10%的内存会被“浪费”. 当然,98%的对象可回收只是一般场景下的数据,我们没有办法保证每次回收都只有不多于 10%的对象存活,当Survivor空间不够用时,需要依赖其他内存(这里指老年代)进行分配担保(Handle Promotion). 4、当存活率高时将会出现大量的内存复制操作还有可能导致进行分配担保 3. 标记-整理算法(Mark-Compact) 1、老年代内存,标记可回收对象之后,将存活的对象移向一端,然后清理掉端边界以外的内存 4. 分代收集算法(Generational Collection) 1、将堆内存分为老年代和新生代 2、老年代对象存活率高,再采用标记-清理或标记-整理算法进行GC 3、新生代存活率低,采用复制算法将少量的存活对象进行复制操作 五. HotSpot算法实现1. 枚举根节点 1、虚拟机内OopMap存有对象引用信息，可以得到GC Root根节点 2. 安全点 1、虚拟机会在如方法调用、 循环跳转、 异常跳转等，所以具有这些功能的指令才会产生Safepoint 2、中断方式 抢先式中断(基本弃用): 给出中断指令，有线程发现未到达安全点则继续执行至下一个安全点 主动式中断: 给定一个中断标志，每个线程都会去轮询该标志，为真时中断 3. 安全区域 1、安全区域是指在一段代码片段之中，引用关系不会发生变化。 在这个区域中的任意地方开始GC都是安全的 2、在线程执行到安全区域时首先会标记自己进入安全区域，出安全区域前必须等到枚举根节点或整个GC完成，没有则都等到可以出安全区域信号为止 六. 垃圾回收器 1. Serial收集器 1、JDK1.3.1之前是虚拟机新生代收集的唯一选择 2、单线程、Stop The World(STW)、复制算法 3、Client模式下新生代默认的垃圾收集器 2. PerNew收集器 1、Serial收集器的多线程版,其他一样 2、是许多虚拟机Server模式下新生代的首选收集器 3、ParNew收集器也是使用-XX:+UseConcMarkSweepGC选项后的默认新生代收集器,也可以使用-XX:+UseParNewGC选项来强制指定它 4、单核下效果不一定比Serial效果好,多核更适合,-XX:ParallelGCThreads参数来限制垃圾收集的线程数 3. Parallel Scavenge收集器 1、新生代收集器,采用复制算法,并行的多线程收集器,吞吐量优先 2、追求可控的吞吐量, 吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间) 3、控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数. 4. Serial Old收集器 1、Serial老年代版本、单线程、标记-整理算法 2、给Client模式下虚拟机用 5. Parallel Old收集器 1、Parallel Scavenge收集器的老年代版本,使用多线程和“标记-整理”算法,JDK1.6开始提供 6. CMS收集器 1、CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器. 2、标记-清除算法实现 初始标记(CMS initial mark)，有短时的STW 并发标记(CMS concurrent mark) 重新标记(CMS remark)，有短时的STW 并发清除(CMS concurrent sweep) 3、并发收集、 低停顿,Sun公司的一些官方文档中也称之为并发低停顿收集器 4、-XX：+UseCMSCompactAtFullCollection默认开启，表示CMS进行Full GC的时候开启内存碎片的合并整理，该过程无法并发停顿时间变长 5、-XX：CMSFullGCsBeforeCompaction表示执行多少次不压缩的Full GC后跟着来一次压缩的Full GC，默认是0，每次都压缩 7. G1收集器 1、G1(Garbage-First)收集器是当今收集器技术发展的最前沿成果之一,面向服务端应用 2、特点: 并发与并行:充分利用cpu与多核等硬件优势 分代收集: 空间整理:标记-整理算法 可预测的停顿:将堆内存分为多个区域(Region),还保留有老年代与新生代 3、不计算维护Remembered Set的操作,G1收集器的运作大致可划分为以下几个步骤: 初始标记(Initial Marking) 并发标记(Concurrent Marking) 最终标记(Final Marking) 筛选回收(Live Data Counting and Evacuation) 8. 垃圾收集器参数 参数 描述 UseSerialGC Client模式下默认,使用Serial+Serial Old组合 UseParNewGC ParNew+Serial Old组合 UseConMarkSweepGC ParNew+CMS+Serial Old组合,Serial Old作为CMS失败后备用 UseParallelGC Server模式默认,Parallel Scavenge+Serial Old(PS Mark Sweep)组合 UseParallelOldGC Parallel Scavenge+Parallel Old组合 UseG1GC 使用G1 七. 内存分配与回收策略1. 对象优先在Eden分配 对象优先在Eden新生代分配,内存不足将发生一次Minor GC 2. 大对象直接进入老年代 -XX:PretenureSizeThreshold参数,令大于这个设置值的对象直接在老年代分配,避免大量内存复制 3. 长期存活的对象将进入老年代 对象晋升老年代的年龄阈值,可以通过参数-XX:MaxTenuringThreshold设置,默认15,每次Minor GC对象没死+1 4. 动态对象年龄判定 如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等 到MaxTenuringThreshold中要求的年龄 5. 空间分配担保 Minor GC前先判断老年代可用空间是否大于新生代对象总空间,如果大于则确保安全,如果小于则查看HandlePromotionFailure设置的值是否 允许担保失败,若允许则会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小,如果大于,将尝试着进行一次Minor GC,尽管这次Minor GC是有风险的;如果小于,或者HandlePromotionFailure设置不允许冒险,那这时也要改为进行一次Full GC. 八. Minor GC、Major GC与Full GC Minor GC表示新生代GC、Major GC是指老年代GC、Full GC为全部堆内存GC。 往往他们之间相互影响，相互触发]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Collection Frame]]></title>
    <url>%2F2018%2F06%2F15%2Fjava-collection-frame%2F</url>
    <content type="text"><![CDATA[1. JAVA集合框架图 集合框架 集合框架-简图 2. ArrayList、LinkedList、Vector、Stack 都是java的可存储重复元素的集合容器,都实现了Collection、List接口 ArrayList是基于数组的可动态扩展的、可存储重复元素的、有默认顺序的集合，非线程安全的，最大元素个数为Integer.MAX_VALUE个 由于是基于数组的所以add(E)、get(i)效率较高，set(i,E)、remove(i)、add(i,E)效率较低 LinkedList是基于双向链表的可动态扩展的、可存储重复元素的、非线程安全的有序集合。 由于是基于链表的所以add(E)、add(i,E)、set(i,E)、remove(i)效率较高，get(i)效率较低 Vector是基于数组的可动态扩展的、可存储重复元素的、线程安全的有序集合 由于是线程安全的所以效率比上诉的都要低 Stack(栈),继承了Vector,只有push(入栈)、pop(出栈)、peek(查看)等方法实现 3. HashSet、LinkedHashSet、TreeSet 都是java的不可存储重复元素的集合容器,都实现了Collection、Set接口 HashSet是不重复的(hashcode去重)、非线程安全的无序集合 只能放一个null LinkedHashSet是不重复的(hashcode去重)、非线程安全的有序集合 TreeSet是SortedSet唯一实现类，TreeSet可实现自定义排序(实现Comparable接口) 4. HashMap、HashTable、ConcurrentHashMap、IdentityHashMap 都是存储形如key-value集合的容器，都实现了Map接口 HashMap是非线程安全的、按key值得hashcode去重的、无序的集合, 能接受key为null HashTable与HashTable类似，区别在于其实现了同步，效率也相较于HashMap低，不能接受key为null的情况 ConcurrentHashMap是线程安全的、引入了分割(segmentation)，不论它变得多么大，仅仅需要锁定map的某个部分，而其它的线程不需 要等到迭代完成才能访问map。简而言之在迭代的过程中，ConcurrentHashMap仅仅锁定map的某个部分，而Hashtable则会锁定整个map, 所以ConcurrentHashMap效率高于HashTable, 不能接受key为null的情况ConcurrentHashMap实现锁分段技术是通过可重入锁ReentrantLock实现Segment[]分锁，每个Segment内部存放一个或多个HashEntry[] 每个HashEntry又是一个链表，具体的数据结构如图： IdentityHashMap基于数组的、区别于HashMap的是比较key值是比较引用相等(形如object1 == object2)的，HashMap是equals() 判断是否相等的，能接受key为null]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Concurrent]]></title>
    <url>%2F2018%2F06%2F15%2Fjava-concurrent%2F</url>
    <content type="text"><![CDATA[1. JAVA与线程1.1. 线程的实现 实现方式:使用内核线程实现、 使用用户线程实现和使用用户线程加轻量级进程混合实现. JDK1.2之前是基于用户线程实现的，JDK1.2及以后是基于操作系统原生线程模型实现的. 1.2. Java线程调度 线程调度是指系统为线程分配处理器使用权的过程,主要调度方式有两种,分别是协同式线程调度(Cooperative Threads-Scheduling) 和抢占式线程调度(Preemptive ThreadsScheduling) 协同式线程调度:线程的执行时间由线程本身来控制,线程把自己的工作执行完了之后,要主动通知系统切换到另外一个线程上; 优点是实现简单,缺点是线程执行时间不可控制,容易线程阻塞 每个线程将由系统来分配执行时间,线程的切换不由线程本身来决定(在Java中,Thread.yield()可以让出执行时间,但是要获取执行时 间的话,线程本身是没有什么办法的);优点是线程的执行时间是系统可控的,也不会有一个线程导致整个进程阻塞的问题. JAVA线程有10个优先级(Thread.MIN_PRIORITY至Thread.MAX_PRIORITY) 1.3. 线程转换状态 JAVA线程定义了6个状态: 新建(New):创建后尚未启动的线程处于这种状态. 运行(Runable):Runable包括了操作系统线程状态中的Running和Ready,也就是处于此状态的线程有可能正在执行,也有可能正在等待着CPU为它分配执行时间. 无限期等待(Waiting):处于这种状态的线程不会被分配CPU执行时间,它们要等待被其他线程显式地唤醒. 以下方法会让线程陷入无限期的等待状态:● 没有设置Timeout参数的Object.wait()方法.● 没有设置Timeout参数的Thread.join()方法.● LockSupport.park()方法. 限期等待(Timed Waiting):处于这种状态的线程也不会被分配CPU执行时间,不过无须等待被其他线程显式地唤醒,在一定时间之后它们会由系统自动唤醒. 以下方法会让线程进入限期等待状态:● Thread.sleep()方法.● 设置了Timeout参数的Object.wait()方法.● 设置了Timeout参数的Thread.join()方法.● LockSupport.parkNanos()方法.● LockSupport.parkUntil()方法 阻塞(Blocked):该状态程序在等待获取一个排他锁，程序在同步时会在该状态 结束(Terminated):已终止线程的线程状态,线程已经结束执行. 线程状态转换关系图 2. 线程安全与锁优化2.1. JAVA中的线程安全 共享数据分类 不可变(Immutable):不可变对象一定是线程安全的,典型的final 绝对线程安全: 相对线程安全: java大部分的线程安全都是相对线程安全的 线程兼容: 线程对立: 2.2. synchronized的优化 synchronized自JDK1.6后引入偏向锁和轻量级锁后大大提升了并发的性能 synchronized锁升级偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁 所以在锁高竞争下Lock性能更高 3. 锁介绍3.1. 自旋锁 自旋锁可以使线程在没有取得锁的时候，不被挂起，而转去执行一个空循环，（即所谓的自旋，就是自己执行空循环），若在若干个空循环后，线 程如果可以获得锁，则继续执行。若线程依然不能获得锁，才会被挂起。使用自旋锁后，线程被挂起的几率相对减少，线程执行的连贯性相对加 强。因此，对于那些锁竞争不是很激烈，锁占用时间很短的并发线程，具有一定的积极意义，但对于锁竞争激烈，单线程锁占用很长时间的并发 程序，自旋锁在自旋等待后，往往毅然无法获得对应的锁，不仅仅白白浪费了CPU时间，最终还是免不了被挂起的操作 ，反而浪费了系统的资源。 在JDK1.6中，Java虚拟机提供-XX:+UseSpinning参数来开启自旋锁，使用-XX:PreBlockSpin参数来设置自旋锁等待的次数。在JDK1.7 开始，自旋锁的参数被取消，虚拟机不再支持由用户配置自旋锁，自旋锁总是会执行，自旋锁次数也由虚拟机自动调整。 问题： 可能白占用CPU时间 死锁问题，自己占用锁，还在等待锁释放 3.2. 阻塞锁 让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进 入运行状态。JAVA中，能够进入\退出、阻塞状态或包含阻塞锁的方法有 ，synchronized 关键字（其中的重量锁），ReentrantLock， Object.wait()\notify() 3.3. 可重入锁 可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。在JAVA环境下 ReentrantLock 和synchronized 都是 可重入锁 3.4. 乐观锁和悲观锁 悲观锁: 每次拿数据都上锁，如行锁、表锁、读锁、写锁 乐观锁: 每次拿数据都不上锁，只是在修改前验证下数据在此期间有无更新，如版本号控制 3.5. 轮询锁和定时锁 由tryLock实现，与无条件获取锁模式相比，它们具有更完善的错误恢复机制。可避免死锁的发生：boolean tryLock():仅在调用时锁为空闲状态才获取该锁。如果锁可用，则获取锁，并立即返回值true。如果锁不可用，则此方法将立即返回 值false。boolean tryLock(long time, TimeUnit unit) throws InterruptedException:如果锁在给定的等待时间内空闲，并且当前 线程未被中断，则获取锁。 3.6. 显示锁和内置锁 显示锁用Lock来定义、内置锁用synchronized。 3.7. 对象锁和类锁 对象锁是用于实例对象(可有多个实例对象)方法上的 类锁是作用于对象的静态方法和Class(一个类只有一个Class对象)对象上的 3.8. 互斥锁 互斥锁, 指的是一次最多只能有一个线程持有的锁。如Java的Lock 3.9 锁粗化 将多个连续的锁操作合并成一个整体的锁 3.10. 锁消除 通过逃逸分析，能证明堆上数据不会逃逸出当前线程，则认为是线程安全的，不必要加锁操作 4. java线程池4.1. 线程池实现类 (C)ThreadPoolExecutor --&gt; (AC)AbstractExecutorService --&gt; (I)ExecutorService --&gt; (I)Executor 4.2. ThreadPoolExecutor构造参数说明 // corePoolSize 核心线程数，当任务多于核心线程数时会进入缓冲阻塞队列workQueue// maximunPoolSize 线程池最大线程数// keepAliveTime 多于核心线程数的空闲线程最长存活时间量级与unit参数配合使用// unit 线程等待时间的单位级// workQueue 任务缓冲队列// threadFactory 线程工厂，用于创建线程// handler 表示拒接处理任务的策略有一下4种：// - ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常// - ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常// - ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）// - ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue);public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory);public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler);public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); 4.3. 实现原理 线程池状态： RUNNING: 线程池初始化时就是RUNNING状态，表示线程池能够接受任务并处理，并且线程池中线程数默认为0(可以通过调用方法 prestartAllCoreThreads() #创建核心线程或者prestartCoreThread() #创建一个核心线程来初始化线程数) SHUTDOWN: 线程处于SHUTDOWN状态时,不接收新任务,但能处理已添加的任务;状态切换调用shutdown()时从RUNNING-&gt; SHUTDOWN STOP: 线程处于STOP状态时，不接收新任务，不处理已添加任务，并会终止正在执行的任务;状态切换调用shutdownNow()时从 RUNNING or SHUTDOWN -&gt; STOP TIDYING: 当所有任务已终止，任务数量为0时，线程池会进入TIDYING状态，并且会执行钩子函数terminated()，用户可重载该方法 实现自己的业务逻辑;状态切换是所有任务终止就进入TIDYING状态 TERMINATED: 线程池彻底终止状态;状态切换是TIDYING的钩子函数执行完毕后进入TERMINATED状态 任务执行过程 当任务提交给线程池时，线程首先判断当前池内线程数是否大于corePoolSize(核心线程数)，如果小于这值就会创建一个新的线程来执行该任务； 当线程数大于核心线程数时，则会尝试将任务放入缓冲队列(workQueue)内，若添加成功，则该任务会被等待的空闲线程取去执行， 若添加失败，则会尝试创建新的线程去执行该任务； 如果线程池内线程数达到了maximumPoolSize(最大线程数)时，则会采取handler(拒绝策略)处理 如果线程池内的线程数大于corePoolSize时，当线程空闲超时keepAliveTime时，线程将被终止，直到线程数等于corePoolSize； 如果允许核心线程数也有超时时间，则当核心线程数内的线程超时时也会被终止，直至线程数为0 线程池中的线程初始化 prestartCoreThread()：初始化一个核心线程 prestartAllCoreThreads()：初始化所有核心线程 初始化后线程会执行workQueue的take()方法，该方法是阻塞的，直到有任务提交 任务缓存队列及排队策略 ArrayBlockingQueue：基于数组的FIFO阻塞队列,必须有最大容量的参数 LinkedBlockingQueue: 基于链表的FIFO阻塞队列,容量动态扩展 SynchronousQueue: 该队列不保存提交的任务，而是直接新建队列来执行任务 任务拒绝策略 ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 线程池的关闭 shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务 shutdownNow(): 立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 线程池容量动态调整 setCorePoolSize()：设置核心池大小 setMaximumPoolSize()：设置线程池最大能创建的线程数目大小 4.4. Executors newFixedThreadPool: 定容量的线程池，核心线程数与最大线程数相等 newSingleThreadExecutor: 单线程线程池，线程池内核心线程数与最大线程数为1 newCachedThreadPool: 无线大小线程池，核心线程数为0，最大线程数为Integer.MAX_VALUE, 缓冲队列为SynchronousQueue newScheduledThreadPool：创建一个ScheduledThreadPoolExecutor定时执行线程池,最大线程数为Integer.MAX_VALUE,内部是 一个DelayedWorkQueue实现 newSingleThreadScheduledExecutor: 创建一个ScheduledThreadPoolExecutor定时执行线程池,最大线程数为Integer.MAX_VALUE, 内部是一个DelayedWorkQueue实现 5. AbstractQueuedSynchronizer 内部类： ConditionObject： Node：存放线程信息队列 5.1. AQS之ReentrantLock独占锁源码分析 AbstractQueuedSynchronizer独占锁 ReentrantLock.lock()保证在ReentrantLock.unlock()之间的代码只有一个线程在执行；ReentrantLock为可重入锁，它有一个与 锁相关的获取计数器，如果拥有锁的某个线程再次得到锁，那么获取计数器就加1，然后锁需要被释放两次才能获得真正释放。 内部类Syn实现了AbstractQueuedSynchronizer接口 构造方法有公平锁和非公平锁，公平锁与非公平锁的区别在于公平锁在尝试获取锁时会放入等待队列的后面，获取锁的顺序是按先后顺序执行的， 而非公平锁在尝试获取锁时首先会去尝试获取锁，若获取失败在进入等待队列按顺序执行。 5.2. AQS之CountDownLatch共享锁源码分析 AbstractQueuedSynchronizer共享锁 CountDownLatch.countDown()实现锁计数-1，直到减至0是，唤醒CountDownLatch.await()等待线程 5.3. 公平锁和非公平锁 公平锁是严格按照FIFO队列获得锁，但带来了大量的线程切换的消耗，非公平锁极大的降低了线程切换带来的消耗，虽然可能造成线程饥饿的情况，但也提高了吞吐量。 6. synchronized与Lock比较 synchronized是JVM层面实现的重量级锁，可通过监控工具监控synchronized的锁定，而且代码出现异常时会自动释放锁 Lock是纯JAVA实现的，为多种实现留下空间，可以实现不同的调度算法、性能特性或者锁定语义，Lock必须自己手动的释放锁 形如finally{lock.unlock();} 当锁竞争激烈时用Lock,锁竞争较弱时用synchronized 7. 阻塞队列BlockingQueue 阻塞队列是一个FIFO队列 主要方法 Ops Throws Exception Special Value Blocks Times Out Insert add(o) offer(o) put(o) &amp; offer(o, timeout, timeUnit) Remove remove(o) poll() take() &amp; poll(timeout, timeUnit) Examine element() peek() - 主要实现 ArrayBlockingQueue：基于数组的有界阻塞队列，必须指定长度 LinkedBlockingQueue: 基于链表的有界阻塞队列，长度可指定也可动态扩张，默认长度为Integer.MAX_VALUE SynchronousQueue: 无缓冲区的阻塞队列，put()要阻塞等待take() PriorityBlockingQueue: 优先级阻塞队列，队列元素必须实现Comparator接口，基于数组，自动扩展长度 DelayQueue：一个使用优先级队列实现的无界阻塞队列 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列 注意如果是无界阻塞队列，队列不可能会出现满的情况，所以使用put或offer方法永远不会被阻塞，而且使用offer方法时，该方法永远返回true。 8. ConcurrentLinkedQueue 非阻塞线程安全的FIFO队列，基于单向链表实现，循环CAS操作实现，由于是根据Node.NEXT是否为NULL来判断是否为TAIL节点，因此队列的元素值不可为NULL。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Memory Model]]></title>
    <url>%2F2018%2F06%2F15%2Fjava-memory-model%2F</url>
    <content type="text"><![CDATA[1. 内存模型(JMM) 2. 内存间的交互操作2.1. 定义操作 lock(锁定)：作用于主内存的变量,它把一个变量标识为一条线程独占的状态. unlock(解锁)：作用于主内存的变量,它把一个处于锁定状态的变量释放出来,释放后的变量才可以被其他线程锁定. read(读取)：作用于主内存的变量,它把一个变量的值从主内存传输到线程的工作内存中,以便随后的load动作使用. load(载入)：作用于工作内存的变量,它把read操作从主内存中得到的变量值放入工作内存的变量副本中. use(使用)：作用于工作内存的变量,它把工作内存中一个变量的值传递给执行引擎,每当虚拟机遇到一个需要使用到 变量的值的字节码指令时将会执行这个操作. assign(赋值)：作用于工作内存的变量,它把一个从执行引擎接收到的值赋给工作内存的变量,每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作. store(存储)：作用于工作内存的变量,它把工作内存中一个变量的值传送到主内存中,以便随后的write操作使用. write(写入)：作用于主内存的变量,它把store操作从工作内存中得到的变量的值放入主内存的变量中. 2.2. 约束条件 read和load、store和write必须保证顺序操作,不能单独出现,但不需要连续操作,中间可隔有其他操作 不允许一个线程丢弃它的最近的assign操作,即变量在工作内存中改变了之后必须把该变化同步回主内存. 不允许一个线程无原因地(没有发生过任何assign操作)把数据从线程的工作内存同步回主内存中. 一个新的变量只能在主内存中“诞生”,不允许在工作内存中直接使用一个未被初始化(load或assign)的变量,换句话说,就是对一个变量实施use、 store操作之前,必须先执行过了assign和load操作. 一个变量在同一个时刻只允许一条线程对其进行lock操作,但lock操作可以被同一条线程重复执行多次,多次执行lock后,只有执行相同次数的 unlock操作,变量才会被解锁 如果对一个变量执行lock操作,那将会清空工作内存中此变量的值,在执行引擎使用这个变量前,需要重新执行load或assign操作初始化变量的值. 如果一个变量事先没有被lock操作锁定,那就不允许对它执行unlock操作,也不允许去unlock一个被其他线程锁定住的变量. 对一个变量执行unlock操作之前,必须先把此变量同步回主内存中(执行store、 write操作) 2.3. volatile &emsp;&emsp;假定T表示一个线程,V和W分别表示两个volatile型变量,那么在进行read、 load、 use、 assign、store和write操作时需要满足如下规则: &emsp;&emsp;只有当线程T对变量V执行的前一个动作是load的时候,线程T才能对变量V执行use动作;并且,只有当线程T对变量V执行的后一个动作是use 的时候,线程T才能对变量V执行load动作. 线程T对变量V的use动作可以认为是和线程T对变量V的load、 read动作相关联,必须连续一起出现 (这条规则要求在工作内存中,每次使用V前都必须先从主内存刷新最新的值,用于保证能看见其他线程对变量V所做的修改后的值). &emsp;&emsp;只有当线程T对变量V执行的前一个动作是assign的时候,线程T才能对变量V执行store动作;并且,只有当线程T对变量V执行的后一个动作 是store的时候,线程T才能对变量V执行assign动作. 线程T对变量V的assign动作可以认为是和线程T对变量V的store、 write动作相关联,必须连续一 起出现(这条规则要求在工作内存中,每次修改V后都必须立刻同步回主内存中,用于保证其他线程可以看到自己对变量V所做的修改) &emsp;&emsp;假定动作A是线程T对变量V实施的use或assign动作,假定动作F是和动作A相关联的load或store动作,假定动作P是和动作F相应的对变量V 的read或write动作;类似的,假定动作B是线程T对变量W实施的use或assign动作,假定动作G是和动作B相关联的load或store动作,假定动作 Q是和动作G相应的对变量W的read或write动作. 如果A先于B,那么P先于Q(这条规则要求volatile修饰的变量不会被指令重排序优化,保证代码的执行 顺序与程序的顺序相同). &emsp;&emsp;volatile不仅保证了共享变量的可见性，还通过内存屏障保证了代码执行顺序与程序顺序相同，通过内存屏障来使变量不被指令重排优化 2.4. long和double的非原子性协定 读写操作可分为2次32位操作,所以一定不是原子操作 注：现在商用虚拟机本身几乎都已经实现了原子操作,所以不用volatile修饰符 2.5. 原子性 变量操作的read、load、use、assign、store、write不保证了原子性 通过synchronized对lock、unlock操作也保证了原子性 2.6. 可见性 volatile保证在读取共享变量之前去主内存刷最新值，还保证了最新值能及时同步至主内存 2.7. 有序性 在本线程内观察所有操作都是有序的，在另一个线程观察所有操作都是无序的 2.8. 先发性 先发生的线程对修改了共享变量的值、发送了消息或调用了方法会被后发生的线程所观察到 2.9. 先行发生(happens-before)规则 《JSR-133:Java Memory Model and Thread Specification》定义了如下happens-before规则。 1、程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 2、监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 3、volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 4、传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 5、start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 6、join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 3. 常见比较3.1. volatile与synchronized比较 1、被volatile描述的共享变量通过内存屏障是代码不被指令重排优化，从而保证了共享变量在线程间的可见性，更新变量时会及时的将最新值 同步至主内存，读变量时会及时的去主内存获取最新值，volatile只能修饰变量，只保证可见性，不保证原子性，不能用来同步。 2、synchronized是通过对象头的锁标志位来实现加锁与释放锁，不仅保证可见性，还保证了原子性，只有获得了对象锁的线程才能进入临界区， 其他线程会阻塞等待锁释放后再争抢锁。 3.2. Lock(ReentrantLock)与synchronized比较 1、synchronized是JAVA关键字，Lock是一个java接口，ReentrantLock实现了该接口 2、Lock锁需要在finally{}代码里手动释放，synchronized会自动释放锁 3、Lock根据实现不同有多种锁类型，如公平锁、非公平锁(默认非公平锁) 4、性能方面，在锁竞争很大的情况下Lock性能更优于synchronized]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>JMM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA Monitor Tools]]></title>
    <url>%2F2018%2F06%2F14%2Fjava-monitor-tools%2F</url>
    <content type="text"><![CDATA[一. jps(JVM Process Status Tool)1. 介绍 类似UNIX的ps命令，列出虚拟机正在运行的进程信息 2. 参数 -q: 只输出进程ID -m: 输出主类启动时的参数 -l: 输出主类全名，如果是jar则输出jar路径 -v: 输出虚拟机启动时的JVM参数 二. jstat(JVM Statistics Monitoring Tool)1. 介绍 用于监视虚拟机各种运行状态信息的命令行工具。 它可以显示本地或者远程虚拟机进程中的类装载、 内存、 垃圾收集、 JIT编译等运行数据 2. 格式 jstat[option vmid[interval[s|ms][count]]] 如jstat -class 14232(PID) 520(采样率) 4(采样次数) 3. 参数 -class: 监控类加载数量、卸载数量、总空间以及加载所用时间 -gc: 监控java堆状态，包括Eden区，2个survivor区，老年代，永久代容量、已用空间、GC时间合计等 -gccapacity: 与-gc基本相同，但主要关注java堆各个区域使用到的最大、最小空间 -gcutil: 与-gc基本相同，但主要关注java堆各个区域使用占比 -gccase: 与-gcutil一样，但会额外输出上一次GC的原因 -gcnew: 监控新生代GC状态 -gcnewcapacity: 与-gcnew基本相同，但主要关注的是使用到的最大、最小空间 -gcold: 监控老年代GC状态 -gcoldcapacity: 与-gcold基本相同，但主要关注的是使用道的最大、最小空间 -gcpermcapacity: 输出永久带使用到的最大、最小空间 -compiler: 输出JIT编译过的方法、耗时等信息 -printcompilation: 输出已被JIT编译过的方法 三. jinfo(Configuration Info for Java)1. 介绍 实时地查看和调整虚拟机各项参数 2. 格式 jinfo [option] pid 如 jinfo -flags 14232 3. 参数 -flag &lt;name&gt;: to print the value of the named VM flag. (输出JVM参数名为name的参数信息) -flag +/-&lt;name&gt;: to enable or disable the named VM flag. (添加或除去JVM参数名为name的参数) -flag &lt;name&gt;=&lt;value&gt;: to set the named VM flag to the given value. (设置JVM参数， 如-Xmx=1024m) -flags: to print VM flags. (输出JVM启动参数信息) -sysprops: to print Java system properties. (输出System.getProperties()信息) 四. jmap(Memory Map for Java)1. 介绍 命令用于生成堆转储快照(一般称为heapdump或dump文件) 其他生成dump文件方式:通过参数-XX：+HeapDumpOnOutOfMemoryErrorOOM时生成、-XX：+HeapDumpOnCtrlBreak通过 [Ctrl]+[Break]键让虚拟机生成dump文件、或者Linux通过命令kill -3 pid也能拿到dump 2. 格式 jmap [option] vmid 3. 参数 -dump: 生成java堆转存快照, 格式 -dump:[live, ],format=b,file=&lt;filename&gt;, live表示是否只导出存活的对象 -finalizerinfo: 显示在F-Queen里面等待Finalizer线程执行finalize()方法的对象，只在Linux/Solaris平台有效 -heap: 显示java堆详细信息，如使用哪种GC回收器，参数配置、分代状况等信息，只在Linux/Solaris平台有效 -histo: 显示堆中对象统计信息，包括类、实例数量及合计容量等 -permstat: 以ClassLoader为统计口径显示永久带内存状态，只在Linux/Solaris平台有效 -F: 当-dump没响应时，使用-F强制生成dump文件，只在Linux/Solaris平台有效 五. jhat(JVM Heap Analysis Tool)1. 介绍 分析jmap生成的堆转储快照(dump文件) 2. 格式 jhat [-port 7001] &lt;dumpfile&gt; 3. 参数 -port: server端口，可通过host:port访问 &lt;file&gt;: dump文件 -J&lt;flag&gt;: 运行参数,如: -J-mx512m 六. jstack(Stack Trace for Java)1. 介绍 用于生成虚拟机当前时刻的线程快照(一般称为threaddump或者javacore文件) 线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因， 如线程间死锁、 死循环、 请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。 线程出现停顿的时候通过 jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源 2. 格式 jstack [option] vmid 如jstack -l 14232 3. 参数 -F: 当正常请求无响应时，强制输出线程堆栈 -l: 除堆栈外，显示关于锁的附加信息 -m: 如果调用到本地方法时，显示C/C++堆栈信息 4. 日志分析 线程分为New、Runnable、Running、Waiting、Timed_Waiting、Blocked、Dead等状态 New: 当线程对象创建时存在的状态，此时线程不可能执行； Runnable：当调用thread.start()后，线程变成为Runnable状态。只要得到CPU，就可以执行； Running：线程正在执行； Waiting：执行thread.join()或在锁对象调用obj.wait()等情况就会进该状态，表明线程正处于等待某个资源或条件发生来唤醒自己； Timed_Waiting：执行Thread.sleep(long)、thread.join(long)或obj.wait(long)等就会进该状态，与Waiting的区别在于Timed_Waiting的等待有时间限制； Blocked：如果进入同步方法或同步代码块，没有获取到锁，则会进入该状态； Dead：线程执行完毕，或者抛出了未捕获的异常之后，会进入dead状态，表示该线程结束 其次，对于jstack日志，我们要着重关注如下关键信息 Deadlock：表示有死锁 Waiting on condition：等待某个资源或条件发生来唤醒自己。具体需要结合jstacktrace来分析，比如线程正在sleep，网络读写繁忙而等待 Blocked：阻塞 Waiting on monitor entry：在等待获取锁 in Object.wait()：获取锁后又执行obj.wait()放弃锁 对于Waiting on monitor entry 和 inObject.wait()的详细描述：Monitor是 Java中用以实现线程之间的互斥与协作的主要手段， 它可以看成是对象或者Class的锁。每一个对象都有，也仅有一个 monitor。从下图中可以看出，每个 Monitor在某个时刻，只能被一个 线程拥有，该线程就是 “Active Thread”，而其它线程都是 “Waiting Thread”，分别在两个队列 “Entry Set”和 “Wait Set”里面 等候。在 “Entry Set”中等待的线程状态是”Waiting for monitor entry”，而在 “Wait Set”中等待的线程状态是 “in Object.wait()” 5. 附录 在JDK1.5中在java.lang.Thread类中新增了getAllStackTraces()方法获取虚拟机所有的线程StackTraceElement 对象，实现了大部分jstack功能，实际项目中可页面展示 七. VisualVM(All-in-One Java Troubleshooting Tool)1. 介绍 是到目前为止随JDK发布的功能最强大的运行监视和故障处理程序，并且可以预见在未来一段时间内都是官方主力发展的虚拟机故障处理工具。 官方在VisualVM的软件说明中写上了“All-in-One”的描述字样，预示着它除了运行监视、 故障处理外，还提供了很多其他方面的功能。 2. 远程监控 1、远程服务器启动jstatd服务创建配置文件jstatd.policy内容为 grant codebase &quot;file:$&#123;java.home&#125;/../lib/tools.jar&quot; &#123; permission java.security.AllPermission; &#125;; 启动服务:jstatd -J-Djava.security.policy=jstatd.policy -p 8701 2、启动应用参数 -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=9090 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false-Djava.rmi.server.hostname=192.168.0.1 3、启动jvisualvm,操作步骤:远程 -&gt; 添加远程主机 -&gt; 添加JMX链接 八. 案列1. 利用jstack调试线程堆栈信息 jps得到PID，如14232 查看进程PID的线程耗时情况,命令ps -Lfp pid或top -Hp pid找到最耗时的线程ID 如14253 获取线程ID16进制编码print &quot;%x\n&quot; 14253为37ad 用jstack获取线程堆栈信息jstack 14232 |grep 37ad打印如下信息:&quot;VM Periodic Task Thread&quot; os_prio=0 tid=0x00007f772c00f800 nid=0x37ad waiting on condition通过该日志分析表示该线程在等待某个资源来唤醒]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java Monitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Interview Experience]]></title>
    <url>%2F2018%2F05%2F19%2Finterview-experience%2F</url>
    <content type="text"><![CDATA[一. JAVA基础1. 9种基本数据类型及其封装类,所占大小 类型 包装类 大小(字节) byte Byte 1 char Character 2 short Short 2 int Integer 4 float Float 4 double Double 8 long Long 8 boolean Boolean - void Void - 2. Object类方法 getClass() 获取类对象Class (native) hashCode() 获取hashCode值(native) equals(Object) 判断是否同一对象 clone() 对象克隆(native) wait() wait(timeout) wait(timeout, nanos) notify() notifyAll() toString() finalize() (protected) 3. equals 、hashCode、== 比较 equals是Object类方法，内部实现的是判断对象是否相等(即 ==)。 hashCode是Object的native方法，返回的是类似表示对象地址的整数。 ==是判断2个对象是否相同。 如果2个对象相同则hashCode一定相等，若2个对象不同hashCode不一定相等。 一般地重写了equals方法建议也要重写hashCode方法。 4. 面向对象的特性与含义 抽象 是将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象两方面。抽象只关注对象有哪些属性和行为，并不 关注这些行为的细节是什么。 封装 是指将某事物的属性和行为包装到对象中，这个对象只对外公布需要公开的属性和行为，而这个公布也是可以有选择性的公布 给其它对象，private、protected、public三种修饰符或不用(即默认default)对外部对象访问该对象的属性和行为进行限制。 继承 是子对象可以继承父对象的属性和行为，亦即父对象拥有的属性和行为，其子对象也就拥有了这些属性和行为。 多态 是指父对象中的同一个行为能在其多个子对象中有不同的表现。也就是说子对象可以使用重写父对象中的行为,使其拥有不同于 父对象和其它子对象的表现,这就是overriding(重写)。实现多态的技术称为：动态绑定(dynamic binding)，是指在执行期间判 断所引用对象的实际类型，根据其实际的类型调用其相应的方法。 5. Override与Overload Override是重写:方法名称、参数个数，类型，顺序，返回值类型都是必须和父类方法一致的。它的关系是父子关系。 Overload是重载:方法名称不变，方法参数个数、类型、顺序至少一个不同。它的关系是同一个类，同一个方法名。 6. wait与sleep wait是Object类的方法；而sleep是Thread类的静态方法。 当线程执行到wait方法时，他就会进入到该对象相关的等待池中，同时释放对象的机锁，其他线程可访问，直到超时或该对象调用notify 或notifyAll；而当线程执行sleep方法时，线程进入阻塞状态，让出CPU资源，但在Synchronized同步块中不能释放对象的锁。 wait方法必须放在synchronized代码块中，否则会在时抛出java.lang.IllegalMonitorStateException异常。 wait和sleep都可以通过interrupt()方法打断线程的暂停状态，从而使线程立刻抛出InterruptedException(但不建议使用该方法)。 7. java并发 Java并发编程 8. interface与abstract类 抽象类是包含有抽象方法的类(也可以拥有成员变量和普通成员方法)，抽象方法是只有方法声明没有具体实现的方法，所以抽象类不能实例化，是为 了继承而存的，抽象类与普通类有3点区别： 1.抽象方法必须是public或protected，缺损情况下默认为public; 2.抽象类不能被实例化； 3.如果一个类继承了抽象类，则子类必须实现父类的抽象方法，若没有实现父类抽象方法，则子类也必须定义为抽象类。 接口是泛指供别人调用的方法或函数，接口中可以有变量和方法，变量被隐式地指定为public static final，方法被隐式地指定为 public abstract,接口中的方法不能有具体的实现(JDK8之后接口可以有default方法)。 接口与抽象类比较: 1.语法层面上: 1).抽象类可以提供成员方法的实现细节而接口中只能存在public abstract方法 2).抽象类中的成员变量可以是各种类型，而接口中的成员变量只能是public static final类型 3).接口中不能存在静态代码块和静态方法，而抽象类中可以 4).一个类只能继承一个抽象类而可以实现多个接口 2.设计层面上: 1).抽象类是对一种事物对象的抽象，而接口是对事物行为的抽象，抽象类是对整个类整体的抽象，包括属性、行为，而接口是对类的局部 (行为)的抽象。继承抽象类是”是不是”的关系，实现接口是”有没有”的关系。 2).设计层面不同，抽象类作为很多子类的父类，它是一种模板式设计，而接口是一种行为规范，它是一种辐射式设计 9. fail-fast fail-fast：机制是java集合(Collection)中的一种错误机制。当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。 例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出异常: ConcurrentModificationException，产生fail-fast事件。 10. JDK和CGLIB动态代理 JDK动态代理只能针对实现了接口的类生成代理(实例化一个类)。此时代理对象和目标对象实现了相同的接口，目标对象作为代理对象的一个属性， 具体接口实现中，可以在调用目标对象相应方法前后加上其他业务处理逻辑。 CGLIB是针对类实现代理，主要是对指定的类生成一个子类(没有实例化一个类)，覆盖其中的方法。 二. JVM1. 内存模型 堆内存(Heap) 是线程间共享内存，主要存放java的对象及数组 栈内存(Stack) 是线程间不共享的，主要存放基本数据类型和对象及数组的引用等 方法区(Method Area) 是存储已被虚拟机加载的类信息、 常量、 静态变量、 即时编译器编译后的代码等数据 本地方法栈(Native Method Stack) 为虚拟机调用本地Native方法提供服务,有的虚拟机与虚拟机栈合二为一 程序计数器(Program Counter Register) 是当前虚拟机执行指令的地址，当执行到Native方法时其值为空(Undefined) 运行时常量池(Runtime Constant Pool) 用于存放编译期生成的各种字面量和符号引用,这部分内容将在类加载后进入方法区的运行时常量池中存放 直接内存(Direct Memory) NIO的DirectByteBuffer对象使用直接内存,这样能在一些场景中显著提高性能,因为避免了在Java堆和Native堆中来回复制数据 2. GC的2种判定方法 引用计数: 实现简单、高效，但会出现循环引用的时候对象将无法得到回收 引用链：即可达性分析，以GC Roots为根节点开始向下搜索，所走的路径叫做引用链(Reference Chain)，当一个对象到GC Roots对象没有 任何引用链时说明该对象不可用，可作为GC Roots的对象： 1.虚拟机栈（栈帧中的本地变量表）中引用的对象。 2.方法区中的类静态属性引用的对象或者常量引用的对象。 3.本地方法栈中JNI（就是native方法）引用的对象。 3. java自动内存管理 Java自动内存管理 三. 其他1. OSI网络模型 层级 名称 描述 1 应用层 指网络操作系统和具体的应用程序，对应WWW服务器、FTP服务器等应用软件 2 表示层 数据语法的转换、数据的传送等 3 会话层 建立起两端之间的会话关系，并负责数据的传送 4 传输层 负责错误的检查与修复，以确保传送的质量，是TCP/UDP工作的地方。（报文） 5 网络层 提供了编址方案,IP协议工作的地方(数据包） 6 数据链路层 将由物理层传来的未经处理的位数据包装成数据帧 7 物理层 对应网线、网卡、接口等物理设备(位) 2. TCP/IP协议 应用层 传输层 网络层 链路层 3. IP分类 A类地址（1.0.0.0-126.255.255.255）用于最大型的网络，该网络的节点数可达16,777,216个。 B类地址（128.0.0.0-191.255.255.255）用于中型网络，节点数可达65,536个。 C类地址（192.0.0.0-223.255.255.255）用于256个节点以下的小型网络的单点网络通信。 D类地址（224.0.0.0-239.255.255.255）并不反映网络的大小，只是用于组播，用来指定所分配的接收组播的节点组，这个节点组由组播订 阅成员组成。D类地址的范围为 E类（240.0.0.0-255.255.255.254）地址用于试验。 4. TCP与UDP TCP、UDP都是传输层协议 TCP(Transmission Control Protocol, 传输控制协议) 是面向连接的协议(即在收发数据前必须和对方建立可靠连接)，TCP建立连接要3次 握手，TCP断开连接需要4次挥手，保证了数据通信的可靠性；TCP包头最小长度为20个字节数。 UDP(User Data Protocol, 用户数据报协议) 是一个非连接的协议(即传输数据之前源端和终端不建立连接)，只是简单的把应用程序的数据 尽快地扔到网络上，因此UDP传输速度只受应用程序生成数据速度、计算机的能力和传输带宽的限制，接收端，UDP把每个消息段放入队列中 应用程序读取使用；UDP可以一台服务器同时向多台客户机传输相同数据；UDP消息头很短只有8个字节；UDP尽可能快的发送数据，但不保证 数据的可靠性(丢包，顺序等)；UDP是面向报文的，发送方的报文只是添加首部后就向下交付给IP层，既不拆分也不合并，这些需要接收端 应用程序自己实现。 5. 死锁的必要条件 互斥条件：资源是独占的且排他使用，进程互斥使用资源，即任意时刻一个资源只能给一个进程使用，其他进程若申请一个资源，而该资源 被另一进程占有时，则申请者等待直到资源被占有者释放。 不可剥夺条件：进程所获得的资源在未使用完毕之前，不被其他进程强行剥夺，而只能由获得该资源的进程资源释放。 请求和保持条件：进程每次申请它所需要的一部分资源，在申请新的资源的同时，继续占用已分配到的资源。 循环等待条件：在发生死锁时必然存在一个进程等待队列{P1,P2,…,Pn},其中P1等待P2占有的资源，P2等待P3占有的资源，…，Pn等待P1占有 的资源，形成一个进程等待环路，环路中每一个进程所占有的资源同时被另一个申请，也就是前一个进程占有后一个进程所深情地资源。 6. MySQL索引(5.5之前默认MyISAM引擎，5.5之后默认InnoDB) MyISAM使用B-Tree实现主键索引、唯一索引和非主键索引。 InnoDB中非主键索引使用的是B-Tree数据结构，而主键索引使用的是B+Tree。 7. 进程与线程 进程是资源的分配和调度的一个独立单元，而线程是CPU调度的基本单元 同一个进程中可以包括多个线程，并且线程共享整个进程的资源（寄存器、堆栈、上下文），一个进行至少包括一个线程。 进程的创建调用fork或者vfork，而线程的创建调用pthread_create，进程结束后它拥有的所有线程都将销毁，而线程的结束不会影响同个进 程中的其他线程的结束 线程是轻量级的进程，它的创建和销毁所需要的时间比进程小很多，所有操作系统中的执行功能都是创建线程去完成的 线程中执行时一般都要进行同步和互斥，因为他们共享同一进程的所有资源 线程有自己的私有属性TCB，线程id，寄存器、硬件上下文，而进程也有自己的私有属性进程控制块PCB，这些私有属性是不被共享的，用来标 示一个进程或一个线程的标志 8. IPC通信方式 管道(Pipe)：匿名管道（pipe亲缘关系的进程通信）、命名管道（mkfifo/mknod） 消息队列：是基于消息的、用无亲缘关系的进程间通信，主要函数：msgget、msgsend、msgrecv、msgctl 信号量：相当于一把互斥锁，通过p、v操作，主要函数：semget、semop、semctl 共享内存：是进程间通信速度最快的，所以用经常是集合信号量或互斥锁来实现同步，shmget、shmat、shmdt、shmctl 9. 虚拟内存 是将进程部分装入内存中，从而能实现一个很大的程序能在一个比它小的内存中运行，它的主要实现是靠程序的换进换出来实现的，因为内存 中0-3G是用户使用，3-4G才是内存使用，通过映射来实现来进行逻辑地址到物理地址的映射 10. 设计原则 依赖倒置原则 － Dependency Inversion Principle (DIP) 里氏替换原则 － Liskov Substitution Principle (LSP) 接口分隔原则 － Interface Segregation Principle (ISP) 单一职责原则 － Single Responsibility Principle (SRP) 开闭原则 － The Open-Closed Principle (OCP)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Excel4J]]></title>
    <url>%2F2018%2F04%2F16%2FExcel4J%2F</url>
    <content type="text"><![CDATA[Excel4J Github 紧急修复以绝对路径指定模板来导出会导致模板被修改的BUG,以及读取Excel数据会修改原Excel文件,建议升级至2.1.4-Final2及以上版本 一. 更新记录1. v3.x 新增CSV(包含基于ExcelField注解)的导出支持 新增CSV(包含基于ExcelField注解)的导入支持 2. v2.x Excel读取支持部分类型转换了(如转为Integer,Long,Date(部分)等) v2.0.0之前只能全部内容转为String Excel支持非注解读取Excel内容了,内容存于List&lt;List&lt;String&gt;&gt;对象内 现在支持List&lt;List&lt;String&gt;&gt;导出Excel了(可以不基于模板) Excel新增了Map数据样式映射功能(模板可为每个key设置一个样式,定义为:&amp;key, 导出Map数据的样式将与key值映射) 新增读取Excel数据转换器接口com.github.converter.ReadConvertible 新增写入Excel数据转换器接口com.github.converter.WriteConvertible 支持多sheet一键导出，多sheet导出封装Wrapper详见com.github.sheet.wrapper包内包装类 修复以绝对路径指定模板来导出会导致模板被修改的BUG,以及读取Excel数据会修改原Excel文件,建议升级至2.1.4-Final2版本 修复已知bug及代码与注释优化 二. 基于注解(/src/test/java/modules/Student2.java)@ExcelField(title = "学号", order = 1)private Long id;@ExcelField(title = "姓名", order = 2)private String name;// 写入数据转换器 Student2DateConverter@ExcelField(title = "入学日期", order = 3, writeConverter = Student2DateConverter.class)private Date date;@ExcelField(title = "班级", order = 4)private Integer classes;// 读取数据转换器 Student2ExpelConverter@ExcelField(title = "是否开除", order = 5, readConverter = Student2ExpelConverter.class)private boolean expel; 三. 读取Excel快速实现1.待读取Excel(截图) 2. 读取转换器(/src/test/java/converter/Student2ExpelConverter.java)/** * excel是否开除 列数据转换器 */public class Student2ExpelConverter implements ReadConvertible&#123; @Override public Object execRead(String object) &#123; return object.equals("是"); &#125;&#125; 3. 读取函数(/src/test/java/base/Excel2Module.java#excel2Object2)@Testpublic void excel2Object2() &#123; String path = "D:\\JProject\\Excel4J\\src\\test\\resources\\students_02.xlsx"; try &#123; // 1) // 不基于注解,将Excel内容读至List&lt;List&lt;String&gt;&gt;对象内 List&lt;List&lt;String&gt;&gt; lists = ExcelUtils.getInstance().readExcel2List(path, 1, 2, 0); System.out.println("读取Excel至String数组："); for (List&lt;String&gt; list : lists) &#123; System.out.println(list); &#125; // 2) // 基于注解,将Excel内容读至List&lt;Student2&gt;对象内 // 验证读取转换函数Student2ExpelConverter // 注解 `@ExcelField(title = "是否开除", order = 5, readConverter = Student2ExpelConverter.class)` List&lt;Student2&gt; students = ExcelUtils.getInstance().readExcel2Objects(path, Student2.class, 0, 0); System.out.println("读取Excel至对象数组(支持类型转换)："); for (Student2 st : students) &#123; System.out.println(st); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 4. 读取结果读取Excel至String数组：[10000000000001, 张三, 2016/01/19, 101, 是][10000000000002, 李四, 2017-11-17 10:19:10, 201, 否]读取Excel至对象数组(支持类型转换)：Student2&#123;id=10000000000001, name=&apos;张三&apos;, date=Tue Jan 19 00:00:00 CST 2016, classes=101, expel=&apos;true&apos;&#125;Student2&#123;id=10000000000002, name=&apos;李四&apos;, date=Fri Nov 17 10:19:10 CST 2017, classes=201, expel=&apos;false&apos;&#125;Student2&#123;id=10000000000004, name=&apos;王二&apos;, date=Fri Nov 17 00:00:00 CST 2017, classes=301, expel=&apos;false&apos;&#125; 四. 导出Excel1. 不基于模板快速导出1) 导出函数(/src/test/java/base/Module2Excel.java#testList2Excel)@Testpublic void testList2Excel() throws Exception &#123; List&lt;List&lt;String&gt;&gt; list2 = new ArrayList&lt;&gt;(); List&lt;String&gt; header = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; List&lt;String&gt; _list = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; 10; j++) &#123; _list.add(i + " -- " + j); &#125; list2.add(_list); header.add(i + "---"); &#125; ExcelUtils.getInstance().exportObjects2Excel(list2, header, "D:/D.xlsx");&#125; 2) 导出效果(截图) 2. 带有写入转换器函数的导出1) 转换器(/src/test/java/converter/Student2DateConverter.java)/** * 导出excel日期数据转换器 */public class Student2DateConverter implements WriteConvertible &#123; @Override public Object execWrite(Object object) &#123; Date date = (Date) object; return DateUtils.date2Str(date, DateUtils.DATE_FORMAT_MSEC_T_Z); &#125;&#125; 2）导出函数(/src/test/java/base/Module2Excel.java#testWriteConverter)// 验证日期转换函数 Student2DateConverter// 注解 `@ExcelField(title = "入学日期", order = 3, writeConverter = Student2DateConverter.class)`@Testpublic void testWriteConverter() throws Exception &#123; List&lt;Student2&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; list.add(new Student2(10000L + i, "学生" + i, new Date(), 201, false)); &#125; ExcelUtils.getInstance().exportObjects2Excel(list, Student2.class, true, "sheet0", true, "D:/D.xlsx");&#125; 3) 导出效果(截图) 3. 基于模板List&lt;Oject&gt;导出1) 导出函数(/src/test/java/base/Module2Excel.java#testObject2Excel)@Testpublic void testObject2Excel() throws Exception &#123; String tempPath = "/normal_template.xlsx"; List&lt;Student1&gt; list = new ArrayList&lt;&gt;(); list.add(new Student1("1010001", "盖伦", "六年级三班")); list.add(new Student1("1010002", "古尔丹", "一年级三班")); list.add(new Student1("1010003", "蒙多(被开除了)", "六年级一班")); list.add(new Student1("1010004", "萝卜特", "三年级二班")); list.add(new Student1("1010005", "奥拉基", "三年级二班")); list.add(new Student1("1010006", "得嘞", "四年级二班")); list.add(new Student1("1010007", "瓜娃子", "五年级一班")); list.add(new Student1("1010008", "战三", "二年级一班")); list.add(new Student1("1010009", "李四", "一年级一班")); Map&lt;String, String&gt; data = new HashMap&lt;&gt;(); data.put("title", "战争学院花名册"); data.put("info", "学校统一花名册"); // 基于模板导出Excel ExcelUtils.getInstance().exportObjects2Excel(tempPath, 0, list, data, Student1.class, false, "D:/A.xlsx"); // 不基于模板导出Excel ExcelUtils.getInstance().exportObjects2Excel(list, Student1.class, true, null, true, "D:/B.xlsx");&#125; 2) 导出模板(截图) 3) 基于模板导出结果(截图) 4) 不基于模板导出结果(截图) 4. 基于模板Map&lt;String, Collection&lt;Object.toString&gt;&gt;导出1) 导出函数(/src/test/java/base/Module2Excel.java#testMap2Excel)@Testpublic void testMap2Excel() throws Exception &#123; Map&lt;String, List&gt; classes = new HashMap&lt;&gt;(); Map&lt;String, String&gt; data = new HashMap&lt;&gt;(); data.put("title", "战争学院花名册"); data.put("info", "学校统一花名册"); classes.put("class_one", new ArrayList&lt;Student1&gt;() &#123;&#123; add(new Student1("1010009", "李四", "一年级一班")); add(new Student1("1010002", "古尔丹", "一年级三班")); &#125;&#125;); classes.put("class_two", new ArrayList&lt;Student1&gt;() &#123;&#123; add(new Student1("1010008", "战三", "二年级一班")); &#125;&#125;); classes.put("class_three", new ArrayList&lt;Student1&gt;() &#123;&#123; add(new Student1("1010004", "萝卜特", "三年级二班")); add(new Student1("1010005", "奥拉基", "三年级二班")); &#125;&#125;); classes.put("class_four", new ArrayList&lt;Student1&gt;() &#123;&#123; add(new Student1("1010006", "得嘞", "四年级二班")); &#125;&#125;); classes.put("class_six", new ArrayList&lt;Student1&gt;() &#123;&#123; add(new Student1("1010001", "盖伦", "六年级三班")); add(new Student1("1010003", "蒙多", "六年级一班")); &#125;&#125;); ExcelUtils.getInstance().exportObject2Excel("/map_template.xlsx", 0, classes, data, Student1.class, false, "D:/C.xlsx");&#125; 2) 导出模板(截图) 3) 导出结果(截图) 五. Excel模板自定义属性,不区分大小写1) 具体代码定义详见(/src/main/java/com/github/crab2died/handler/HandlerConstant)2) Excel模板自定义属性,不区分大小写 定义符 描述 优先级(大到小) $appoint_line_style 当前行样式 3 $single_line_style 单行样式 2 $double_line_style 双行样式 2 $default_style 默认样式 1 $data_index 数据插入的起始位置 - $serial_number 插入序号标记 - 六. 多sheet数据导出1. 多sheet数据导出包装类,详见com.github.sheet.wrapper包内包装类 多sheet数据导出只需将待导出数据封装入com.github.sheet.wrapper包内的Wrapper类即可实现多sheet一键导出 2. 无模板、无注解的多sheet导出com.github.sheet.wrapper.SimpleSheetWrapper1) 调用方法// 多sheet无模板、无注解导出@Testpublic void testBatchSimple2Excel() throws Exception &#123; // 生成sheet数据 List&lt;SimpleSheetWrapper&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt;= 2; i++) &#123; //表格内容数据 List&lt;String[]&gt; data = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; 1000; j++) &#123; // 行数据(此处是数组) 也可以是List数据 String[] rows = new String[5]; for (int r = 0; r &lt; 5; r++) &#123; rows[r] = "sheet_" + i + "row_" + j + "column_" + r; &#125; data.add(rows); &#125; // 表头数据 List&lt;String&gt; header = new ArrayList&lt;&gt;(); for (int h = 0; h &lt; 5; h++) &#123; header.add("column_" + h); &#125; list.add(new SimpleSheetWrapper(data, header, "sheet_" + i)); &#125; ExcelUtils.getInstance().simpleSheet2Excel(list, "K.xlsx");&#125; 2) 导出结果(截图) 3. 无模板、基于注解的多sheet导出com.github.sheet.wrapper.NoTemplateSheetWrapper1) 调用方法// 多sheet无模板、基于注解的导出@Testpublic void testBatchNoTemplate2Excel() throws Exception &#123; List&lt;NoTemplateSheetWrapper&gt; sheets = new ArrayList&lt;&gt;(); for (int s = 0; s &lt; 3; s++) &#123; List&lt;Student2&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 1000; i++) &#123; list.add(new Student2(10000L + i, "学生" + i, new Date(), 201, false)); &#125; sheets.add(new NoTemplateSheetWrapper(list, Student2.class, true, "sheet_" + s)); &#125; ExcelUtils.getInstance().noTemplateSheet2Excel(sheets, "EE.xlsx");&#125; 2) 导出结果(截图) 4. 基于模板、注解的多sheet导出com.github.sheet.wrapper.NormalSheetWrapper1) 调用方法(注:为了测试方便，各个sheet数据相同)// 基于模板、注解的多sheet导出@Testpublic void testObject2BatchSheet() throws Exception &#123; List&lt;NormalSheetWrapper&gt; sheets = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 2; i++) &#123; List&lt;Student1&gt; list = new ArrayList&lt;&gt;(); list.add(new Student1("1010001", "盖伦", "六年级三班")); list.add(new Student1("1010002", "古尔丹", "一年级三班")); list.add(new Student1("1010003", "蒙多(被开除了)", "六年级一班")); list.add(new Student1("1010004", "萝卜特", "三年级二班")); list.add(new Student1("1010005", "奥拉基", "三年级二班")); list.add(new Student1("1010006", "得嘞", "四年级二班")); list.add(new Student1("1010007", "瓜娃子", "五年级一班")); list.add(new Student1("1010008", "战三", "二年级一班")); list.add(new Student1("1010009", "李四", "一年级一班")); Map&lt;String, String&gt; data = new HashMap&lt;&gt;(); data.put("title", "战争学院花名册"); data.put("info", "学校统一花名册"); sheets.add(new NormalSheetWrapper(i, list, data, Student1.class, false)); &#125; String tempPath = "/normal_batch_sheet_template.xlsx"; // 基于模板导出Excel ExcelUtils.getInstance().normalSheet2Excel(sheets, tempPath, "AA.xlsx");&#125; 2) 导出模板(截图) (注:为了测试方便，模板样式大致相同，单元格颜色有区别) sheet1模板 sheet2模板3) 导出结果(截图) sheet1导出结果 sheet2导出结果 5. 形如Map&lt;String, Collection&lt;Object.toString&gt;&gt;数据基于模板、注解的多sheet导出com.github.sheet.wrapper.MapSheetWrapper1) 调用方法(注:为了测试方便，各个sheet数据相同)// Map数据的多sheet导出@Testpublic void testMap2BatchSheet() throws Exception &#123; List&lt;MapSheetWrapper&gt; sheets = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 2; i++) &#123; Map&lt;String, List&lt;?&gt;&gt; classes = new HashMap&lt;&gt;(); Map&lt;String, String&gt; data = new HashMap&lt;&gt;(); data.put("title", "战争学院花名册"); data.put("info", "学校统一花名册"); classes.put("class_one", Arrays.asList( new Student1("1010009", "李四", "一年级一班"), new Student1("1010002", "古尔丹", "一年级三班") )); classes.put("class_two", Collections.singletonList( new Student1("1010008", "战三", "二年级一班") )); classes.put("class_three", Arrays.asList( new Student1("1010004", "萝卜特", "三年级二班"), new Student1("1010005", "奥拉基", "三年级二班") )); classes.put("class_four", Collections.singletonList( new Student1("1010006", "得嘞", "四年级二班") )); classes.put("class_six", Arrays.asList( new Student1("1010001", "盖伦", "六年级三班"), new Student1("1010003", "蒙多", "六年级一班") )); sheets.add(new MapSheetWrapper(i, classes, data, Student1.class, false)); &#125; ExcelUtils.getInstance().mapSheet2Excel(sheets, "/map_batch_sheet_template.xlsx", "CC.xlsx");&#125; 2) 导出模板(截图) (注:为了测试方便，模板样式大致相同，单元格颜色有区别) sheet1模板 sheet2模板3) 导出结果(截图) sheet1导出结果 sheet2导出结果 七. CSV文件的操作(完全支持ExcelField注解的所有配置)1. 基于注解读取CSV文件1) 调用方法// 测试读取CSV文件@Testpublic void testReadCSV() throws Excel4JException &#123; List&lt;Student2&gt; list = ExcelUtils.getInstance().readCSV2Objects("J.csv", Student2.class); System.out.println(list);&#125; 2) 读取结果Student2&#123;id=1000001, name=&apos;张三&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=1, expel=&apos;false&apos;&#125;Student2&#123;id=1010002, name=&apos;古尔丹&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=2, expel=&apos;false&apos;&#125;Student2&#123;id=1010003, name=&apos;蒙多(被开除了)&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=6, expel=&apos;false&apos;&#125;Student2&#123;id=1010004, name=&apos;萝卜特&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=3, expel=&apos;false&apos;&#125;Student2&#123;id=1010005, name=&apos;奥拉基&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=4, expel=&apos;false&apos;&#125;Student2&#123;id=1010006, name=&apos;得嘞&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=4, expel=&apos;false&apos;&#125;Student2&#123;id=1010007, name=&apos;瓜娃子&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=5, expel=&apos;false&apos;&#125;Student2&#123;id=1010008, name=&apos;战三&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=4, expel=&apos;false&apos;&#125;Student2&#123;id=1010009, name=&apos;李四&apos;, date=Wed Nov 28 15:11:12 CST 2018, classes=2, expel=&apos;false&apos;&#125; 2. 基于注解导出CSV文件1) 调用方法// 导出csv@Testpublic void testExport2CSV() throws Excel4JException &#123; List&lt;Student2&gt; list = new ArrayList&lt;&gt;(); list.add(new Student2(1000001L, "张三", new Date(), 1, true)); list.add(new Student2(1010002L, "古尔丹", new Date(), 2, false)); list.add(new Student2(1010003L, "蒙多(被开除了)", new Date(), 6, true)); list.add(new Student2(1010004L, "萝卜特", new Date(), 3, false)); list.add(new Student2(1010005L, "奥拉基", new Date(), 4, false)); list.add(new Student2(1010006L, "得嘞", new Date(), 4, false)); list.add(new Student2(1010007L, "瓜娃子", new Date(), 5, true)); list.add(new Student2(1010008L, "战三", new Date(), 4, false)); list.add(new Student2(1010009L, "李四", new Date(), 2, false)); ExcelUtils.getInstance().exportObjects2CSV(list, Student2.class, "J.csv");&#125;// 超大数据量导出csv// 9999999数据本地测试小于1min@Testpublic void testExport2CSV2() throws Excel4JException &#123; List&lt;Student2&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 9999999; i++) &#123; list.add(new Student2(1000001L + i, "路人 -" + i, new Date(), i % 6, true)); &#125; ExcelUtils.getInstance().exportObjects2CSV(list, Student2.class, "L.csv");&#125; 2) 导出结果// 以下为导出CSV文件内容学号,姓名,入学日期,班级,是否开除1000001,张三,2018-11-28T15:11:12.815Z,1,true1010002,古尔丹,2018-11-28T15:11:12.815Z,2,false1010003,蒙多(被开除了),2018-11-28T15:11:12.815Z,6,true1010004,萝卜特,2018-11-28T15:11:12.815Z,3,false1010005,奥拉基,2018-11-28T15:11:12.815Z,4,false1010006,得嘞,2018-11-28T15:11:12.815Z,4,false1010007,瓜娃子,2018-11-28T15:11:12.815Z,5,true1010008,战三,2018-11-28T15:11:12.815Z,4,false1010009,李四,2018-11-28T15:11:12.815Z,2,false 八. 使用(JDK1.7及以上)1) github拷贝项目&gt;&gt; git clone https://github.com/Crab2died/Excel4J.git Excel4J&gt;&gt; package.cmd 2) 最新版本maven引用：&lt;dependency&gt; &lt;groupId&gt;com.github.crab2died&lt;/groupId&gt; &lt;artifactId&gt;Excel4J&lt;/artifactId&gt; &lt;version&gt;3.0.0-Alpha&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>Excel4J</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Excel4J</tag>
      </tags>
  </entry>
</search>
